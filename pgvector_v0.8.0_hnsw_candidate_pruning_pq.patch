diff --git a/Makefile b/Makefile
index 7a4b88c..23cb6da 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@ EXTVERSION = 0.8.0
 MODULE_big = vector
 DATA = $(wildcard sql/*--*--*.sql)
 DATA_built = sql/$(EXTENSION)--$(EXTVERSION).sql
-OBJS = src/bitutils.o src/bitvec.o src/halfutils.o src/halfvec.o src/hnsw.o src/hnswbuild.o src/hnswinsert.o src/hnswscan.o src/hnswutils.o src/hnswvacuum.o src/ivfbuild.o src/ivfflat.o src/ivfinsert.o src/ivfkmeans.o src/ivfscan.o src/ivfutils.o src/ivfvacuum.o src/sparsevec.o src/vector.o
+OBJS = src/bitutils.o src/bitvec.o src/halfutils.o src/halfvec.o src/hnsw.o src/hnswbuild.o src/hnswinsert.o src/hnswscan.o src/hnswutils.o src/hnswvacuum.o src/hnswmeta.o src/ivfbuild.o src/ivfflat.o src/ivfinsert.o src/ivfkmeans.o src/ivfscan.o src/ivfutils.o src/ivfvacuum.o src/sparsevec.o src/vector.o
 HEADERS = src/halfvec.h src/sparsevec.h src/vector.h
 
 TESTS = $(wildcard test/sql/*.sql)
diff --git a/Makefile.win b/Makefile.win
index 8c62f9d..6185597 100644
--- a/Makefile.win
+++ b/Makefile.win
@@ -2,7 +2,7 @@ EXTENSION = vector
 EXTVERSION = 0.8.0
 
 DATA_built = sql\$(EXTENSION)--$(EXTVERSION).sql
-OBJS = src\bitutils.obj src\bitvec.obj src\halfutils.obj src\halfvec.obj src\hnsw.obj src\hnswbuild.obj src\hnswinsert.obj src\hnswscan.obj src\hnswutils.obj src\hnswvacuum.obj src\ivfbuild.obj src\ivfflat.obj src\ivfinsert.obj src\ivfkmeans.obj src\ivfscan.obj src\ivfutils.obj src\ivfvacuum.obj src\sparsevec.obj src\vector.obj
+OBJS = src\bitutils.obj src\bitvec.obj src\halfutils.obj src\halfvec.obj src\hnsw.obj src\hnswbuild.obj src\hnswinsert.obj src\hnswscan.obj src\hnswutils.obj src\hnswvacuum.obj src\hnswmeta.obj src\ivfbuild.obj src\ivfflat.obj src\ivfinsert.obj src\ivfkmeans.obj src\ivfscan.obj src\ivfutils.obj src\ivfvacuum.obj src\sparsevec.obj src\vector.obj
 HEADERS = src\halfvec.h src\sparsevec.h src\vector.h
 
 REGRESS = bit btree cast copy halfvec hnsw_bit hnsw_halfvec hnsw_sparsevec hnsw_vector ivfflat_bit ivfflat_halfvec ivfflat_vector sparsevec vector_type
diff --git a/src/hnsw.c b/src/hnsw.c
index 5bfc619..f1293c6 100644
--- a/src/hnsw.c
+++ b/src/hnsw.c
@@ -30,6 +30,8 @@ int			hnsw_iterative_scan;
 int			hnsw_max_scan_tuples;
 double		hnsw_scan_mem_multiplier;
 int			hnsw_lock_tranche_id;
+bool		hnsw_candidate_pruning;
+int			hnsw_distance_computation_topk;
 static relopt_kind hnsw_relopt_kind;
 
 /*
@@ -74,6 +76,8 @@ HnswInit(void)
 					  HNSW_DEFAULT_M, HNSW_MIN_M, HNSW_MAX_M, AccessExclusiveLock);
 	add_int_reloption(hnsw_relopt_kind, "ef_construction", "Size of the dynamic candidate list for construction",
 					  HNSW_DEFAULT_EF_CONSTRUCTION, HNSW_MIN_EF_CONSTRUCTION, HNSW_MAX_EF_CONSTRUCTION, AccessExclusiveLock);
+	add_bool_reloption(hnsw_relopt_kind, "neighbor_metadata", "Whether to store neighbor metadata to estimate distances",
+					   HNSW_DEFAULT_NEIGHBOR_METADATA, AccessExclusiveLock);
 
 	DefineCustomIntVariable("hnsw.ef_search", "Sets the size of the dynamic candidate list for search",
 							"Valid range is 1..1000.", &hnsw_ef_search,
@@ -93,6 +97,14 @@ HnswInit(void)
 							 NULL, &hnsw_scan_mem_multiplier,
 							 1, 1, 1000, PGC_USERSET, 0, NULL, NULL, NULL);
 
+	DefineCustomBoolVariable("hnsw.candidate_pruning", "Enables candidate pruning for faster scans",
+							 NULL, &hnsw_candidate_pruning,
+							 HNSW_DEFAULT_CANDIDATE_PRUNING, PGC_USERSET, 0, NULL, NULL, NULL);
+
+	DefineCustomIntVariable("hnsw.distance_computation_topk", "Sets the number of neighbors to compute precise distances when using distance estimation",
+							NULL, &hnsw_distance_computation_topk,
+							HNSW_DEFAULT_DISTANCE_COMPUTATION_TOPK, 1, HNSW_MAX_M * 2, PGC_USERSET, 0, NULL, NULL, NULL);
+
 	MarkGUCPrefixReserved("hnsw");
 }
 
@@ -226,6 +238,7 @@ hnswoptions(Datum reloptions, bool validate)
 	static const relopt_parse_elt tab[] = {
 		{"m", RELOPT_TYPE_INT, offsetof(HnswOptions, m)},
 		{"ef_construction", RELOPT_TYPE_INT, offsetof(HnswOptions, efConstruction)},
+		{"neighbor_metadata", RELOPT_TYPE_BOOL, offsetof(HnswOptions, neighborMetadata)},
 	};
 
 	return (bytea *) build_reloptions(reloptions, validate,
diff --git a/src/hnsw.h b/src/hnsw.h
index 1fb0c24..63e84d5 100644
--- a/src/hnsw.h
+++ b/src/hnsw.h
@@ -37,15 +37,22 @@
 #define HNSW_MIN_M	2
 #define HNSW_MAX_M		100
 #define HNSW_DEFAULT_EF_CONSTRUCTION	64
+#define HNSW_DEFAULT_NEIGHBOR_METADATA	true
 #define HNSW_MIN_EF_CONSTRUCTION	4
 #define HNSW_MAX_EF_CONSTRUCTION		1000
 #define HNSW_DEFAULT_EF_SEARCH	40
 #define HNSW_MIN_EF_SEARCH		1
 #define HNSW_MAX_EF_SEARCH		1000
+#define HNSW_DEFAULT_CANDIDATE_PRUNING			true
+#define HNSW_DEFAULT_DISTANCE_COMPUTATION_TOPK	3
 
 /* Tuple types */
 #define HNSW_ELEMENT_TUPLE_TYPE  1
 #define HNSW_NEIGHBOR_TUPLE_TYPE 2
+#define HNSW_CENTROID_TUPLE_TYPE 3
+
+/* Neighbor metadata */
+#define HNSW_NEIGHBOR_METADATA_MAX_BYTES	16
 
 /* Make graph robust against non-HOT updates */
 #define HNSW_HEAPTIDS 10
@@ -60,8 +67,13 @@
 #define HNSW_MAX_SIZE (BLCKSZ - MAXALIGN(SizeOfPageHeaderData) - MAXALIGN(sizeof(HnswPageOpaqueData)) - sizeof(ItemIdData))
 #define HNSW_TUPLE_ALLOC_SIZE BLCKSZ
 
+#define HNSW_NEIGHBOR_TUPLE_ENTRY_MAX_SIZE	(sizeof(ItemPointerData) + HNSW_NEIGHBOR_METADATA_MAX_BYTES)
+
 #define HNSW_ELEMENT_TUPLE_SIZE(size)	MAXALIGN(offsetof(HnswElementTupleData, data) + (size))
-#define HNSW_NEIGHBOR_TUPLE_SIZE(level, m)	MAXALIGN(offsetof(HnswNeighborTupleData, indextids) + ((level) + 2) * (m) * sizeof(ItemPointerData))
+#define HNSW_NEIGHBOR_TUPLE_ENTRY_SIZE(typeInfo, neighborMetadata)	(sizeof(ItemPointerData) + ((neighborMetadata) ? (typeInfo)->neighborMetadataBytes : 0))
+#define HNSW_NEIGHBOR_TUPLE_SIZE(level, m, typeInfo, neighborMetadata)	MAXALIGN(offsetof(HnswNeighborTupleData, entries) + ((level) + 2) * (m) * HNSW_NEIGHBOR_TUPLE_ENTRY_SIZE(typeInfo, neighborMetadata))
+
+#define HNSW_CENTROID_TUPLE_SIZE(dimensions)	MAXALIGN(offsetof(HnswCentroidTupleData, data) + VECTOR_SIZE(dimensions))
 
 #define HNSW_NEIGHBOR_ARRAY_SIZE(lm)	(offsetof(HnswNeighborArray, items) + sizeof(HnswCandidate) * (lm))
 
@@ -86,7 +98,7 @@
 #define HnswGetMl(m) (1 / log(m))
 
 /* Ensure fits on page and in uint8 */
-#define HnswGetMaxLevel(m) Min(((BLCKSZ - MAXALIGN(SizeOfPageHeaderData) - MAXALIGN(sizeof(HnswPageOpaqueData)) - offsetof(HnswNeighborTupleData, indextids) - sizeof(ItemIdData)) / (sizeof(ItemPointerData)) / (m)) - 2, 255)
+#define HnswGetMaxLevel(m) Min(((BLCKSZ - MAXALIGN(SizeOfPageHeaderData) - MAXALIGN(sizeof(HnswPageOpaqueData)) - offsetof(HnswNeighborTupleData, entries) - sizeof(ItemIdData)) / (sizeof(HnswNeighborEntryData)) / (m)) - 2, 255)
 
 #define HnswGetSearchCandidate(membername, ptr) pairingheap_container(HnswSearchCandidate, membername, ptr)
 #define HnswGetSearchCandidateConst(membername, ptr) pairingheap_const_container(HnswSearchCandidate, membername, ptr)
@@ -107,12 +119,19 @@
 #define HnswPtrPointer(hp) (hp).ptr
 #define HnswPtrOffset(hp) relptr_offset((hp).relptr)
 
+/* For neighbor entry access */
+#define HnswNeighborEntryAccess(base, idx, typeInfo, neighborMetadata)	((char *) ((base) + (idx) * HNSW_NEIGHBOR_TUPLE_ENTRY_SIZE(typeInfo, neighborMetadata)))
+#define HnswNeighborEntryItemPointerAccess(base, idx, typeInfo, neighborMetadata)	((ItemPointer) HnswNeighborEntryAccess(base, idx, typeInfo, neighborMetadata))
+#define HnswNeighborEntryMetadataAccess(base, idx, typeInfo, neighborMetadata)		((char *) (HnswNeighborEntryAccess(base, idx, typeInfo, neighborMetadata) + sizeof(ItemPointerData)))
+
 /* Variables */
 extern int	hnsw_ef_search;
 extern int	hnsw_iterative_scan;
 extern int	hnsw_max_scan_tuples;
 extern double hnsw_scan_mem_multiplier;
 extern int	hnsw_lock_tranche_id;
+extern bool hnsw_candidate_pruning;
+extern int	hnsw_distance_computation_topk;
 
 typedef enum HnswIterativeScanMode
 {
@@ -173,6 +192,7 @@ typedef struct HnswSearchCandidate
 {
 	pairingheap_node c_node;
 	pairingheap_node w_node;
+	ItemPointerData  indextid;
 	HnswElementPtr element;
 	double		distance;
 }			HnswSearchCandidate;
@@ -180,9 +200,10 @@ typedef struct HnswSearchCandidate
 /* HNSW index options */
 typedef struct HnswOptions
 {
-	int32		vl_len_;		/* varlena header (do not touch directly!) */
-	int			m;				/* number of connections */
-	int			efConstruction; /* size of dynamic candidate list */
+	int32		vl_len_;			/* varlena header (do not touch directly!) */
+	int			m;					/* number of connections */
+	int			efConstruction;		/* size of dynamic candidate list */
+	bool		neighborMetadata;	/* whether to store neighbor metadata to estimate distances */
 }			HnswOptions;
 
 typedef struct HnswGraph
@@ -214,6 +235,9 @@ typedef struct HnswShared
 	Oid			indexrelid;
 	bool		isconcurrent;
 
+	/* Flag indicating if neighbor metadata is available in shared memory */
+	bool		hasNeighborMetadata;
+
 	/* Worker progress */
 	ConditionVariable workersdonecv;
 
@@ -244,12 +268,14 @@ typedef struct HnswAllocator
 	void	   *state;
 }			HnswAllocator;
 
-typedef struct HnswTypeInfo
+typedef struct HnswNeighborEntryData
 {
-	int			maxDimensions;
-	Datum		(*normalize) (PG_FUNCTION_ARGS);
-	void		(*checkValue) (Pointer v);
-}			HnswTypeInfo;
+	ItemPointerData	indextid;
+	double			distance;
+	char			metadata[HNSW_NEIGHBOR_METADATA_MAX_BYTES];
+}			HnswNeighborEntryData;
+
+typedef HnswNeighborEntryData * HnswNeighborEntry;
 
 typedef struct HnswSupport
 {
@@ -258,6 +284,20 @@ typedef struct HnswSupport
 	Oid			collation;
 }			HnswSupport;
 
+typedef struct HnswTypeInfo
+{
+	int			maxDimensions;
+	Datum		(*normalize) (PG_FUNCTION_ARGS);
+	void		(*checkValue) (Pointer v);
+	/* For type-specific HNSW graph traversal optimization */
+	int			neighborMetadataBytes;
+	Size		(*itemSize) (int dimensions);
+	void		(*updateCenter) (Pointer v, int dimensions, float *x);
+	void		(*sumCenter) (Pointer v, float *x);
+	void		(*setNeighborMetadata)(char *dst, Datum v, void * metastate, HnswSupport * support);
+	void		(*estimateDistances)(Datum q, HnswNeighborEntry entries, int *unvisitedIndexes, int count, void * metastate, HnswSupport * support);
+}			HnswTypeInfo;
+
 typedef struct HnswQuery
 {
 	Datum		value;
@@ -276,6 +316,7 @@ typedef struct HnswBuildState
 	int			dimensions;
 	int			m;
 	int			efConstruction;
+	bool		neighborMetadata;
 
 	/* Statistics */
 	double		indtuples;
@@ -290,6 +331,17 @@ typedef struct HnswBuildState
 	double		ml;
 	int			maxLevel;
 
+	/* Sampling */
+	void			   *samples;
+	BlockSamplerData	bs;
+	ReservoirStateData	rstate;
+	int					rowstoskip;
+
+	/* Neighbor metadata */
+	void	   *neighborMetadataState;
+	FmgrInfo   *kmeansnormprocinfo;		/* Not used */
+	Oid			collation;				/* Not used */
+
 	/* Memory */
 	MemoryContext graphCtx;
 	MemoryContext tmpCtx;
@@ -312,6 +364,16 @@ typedef struct HnswMetaPageData
 	OffsetNumber entryOffno;
 	int16		entryLevel;
 	BlockNumber insertPage;
+
+	/* Neighbor metadata information */
+	bool		hasNeighborMetadata;		/* whether neighbor metadata exists */
+	BlockNumber neighborMetadataStartBlkno;	/* metadata start page number */
+	uint16		neighborMetadataPageCount;	/* number of pages used by metadata */
+	uint16		pqSubvectorDim;				/* PQ subvector dimension */
+	uint16		pqM;						/* PQ number of subvectors */
+
+	/* Dynamic head page position */
+	BlockNumber headBlkno;					/* actual first element page */
 }			HnswMetaPageData;
 
 typedef HnswMetaPageData * HnswMetaPage;
@@ -344,11 +406,22 @@ typedef struct HnswNeighborTupleData
 	uint8		type;
 	uint8		version;
 	uint16		count;
-	ItemPointerData indextids[FLEXIBLE_ARRAY_MEMBER];
+	char		entries[FLEXIBLE_ARRAY_MEMBER];
 }			HnswNeighborTupleData;
 
 typedef HnswNeighborTupleData * HnswNeighborTuple;
 
+typedef struct HnswCentroidTupleData
+{
+	uint8		type;					/* HNSW_CENTROID_TUPLE_TYPE */
+	uint16		subvectorIndex;			/* subvector index */
+	uint16		centroidIndex;			/* centroid index within subvector */
+	uint16		dimensions;				/* dimensions of this centroid */
+	Vector		data;					/* centroid vector */
+}			HnswCentroidTupleData;
+
+typedef HnswCentroidTupleData * HnswCentroidTuple;
+
 typedef union
 {
 	struct pointerhash_hash *pointers;
@@ -359,7 +432,7 @@ typedef union
 typedef union
 {
 	HnswElement element;
-	ItemPointerData indextid;
+	HnswNeighborEntryData entry;
 }			HnswUnvisited;
 
 typedef struct HnswScanOpaqueData
@@ -378,6 +451,9 @@ typedef struct HnswScanOpaqueData
 
 	/* Support functions */
 	HnswSupport support;
+
+	/* Neighbor metadata state */
+	void	   *neighborMetadataState;
 }			HnswScanOpaqueData;
 
 typedef HnswScanOpaqueData * HnswScanOpaque;
@@ -397,6 +473,9 @@ typedef struct HnswVacuumState
 	/* Support functions */
 	HnswSupport support;
 
+	/* Neighbor metadata state */
+	void	   *neighborMetadataState;
+
 	/* Variables */
 	struct tidhash_hash *deleted;
 	BufferAccessStrategy bas;
@@ -410,6 +489,7 @@ typedef struct HnswVacuumState
 /* Methods */
 int			HnswGetM(Relation index);
 int			HnswGetEfConstruction(Relation index);
+bool		HnswSupportNeighborMetadata(Relation index);
 FmgrInfo   *HnswOptionalProcInfo(Relation index, uint16 procnum);
 void		HnswInitSupport(HnswSupport * support, Relation index);
 Datum		HnswNormValue(const HnswTypeInfo * typeInfo, Oid collation, Datum value);
@@ -417,27 +497,28 @@ bool		HnswCheckNorm(HnswSupport * support, Datum value);
 Buffer		HnswNewBuffer(Relation index, ForkNumber forkNum);
 void		HnswInitPage(Buffer buf, Page page);
 void		HnswInit(void);
-List	   *HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation index, HnswSupport * support, int m, bool inserting, HnswElement skipElement, visited_hash * v, pairingheap **discarded, bool initVisited, int64 *tuples);
+List	   *HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, int m, bool inserting, HnswElement skipElement, visited_hash * v, pairingheap **discarded, bool initVisited, int64 *tuples, bool estimateDistances, void * metastate);
 HnswElement HnswGetEntryPoint(Relation index);
+BlockNumber	HnswGetHeadBlockNumber(Relation index);
 void		HnswGetMetaPageInfo(Relation index, int *m, HnswElement * entryPoint);
 void	   *HnswAlloc(HnswAllocator * allocator, Size size);
 HnswElement HnswInitElement(char *base, ItemPointer tid, int m, double ml, int maxLevel, HnswAllocator * alloc);
 HnswElement HnswInitElementFromBlock(BlockNumber blkno, OffsetNumber offno);
-void		HnswFindElementNeighbors(char *base, HnswElement element, HnswElement entryPoint, Relation index, HnswSupport * support, int m, int efConstruction, bool existing);
+void		HnswFindElementNeighbors(char *base, HnswElement element, HnswElement entryPoint, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, int m, int efConstruction, bool existing);
 HnswSearchCandidate *HnswEntryCandidate(char *base, HnswElement em, HnswQuery * q, Relation rel, HnswSupport * support, bool loadVec);
 void		HnswUpdateMetaPage(Relation index, int updateEntry, HnswElement entryPoint, BlockNumber insertPage, ForkNumber forkNum, bool building);
-void		HnswSetNeighborTuple(char *base, HnswNeighborTuple ntup, HnswElement e, int m);
+void		HnswSetNeighborTuple(char *base, HnswNeighborTuple ntup, HnswElement e, int m, const HnswTypeInfo * typeInfo, HnswSupport * support, void * metastate, bool neighborMetadata);
 void		HnswAddHeapTid(HnswElement element, ItemPointer heaptid);
 HnswNeighborArray *HnswInitNeighborArray(int lm, HnswAllocator * allocator);
 void		HnswInitNeighbors(char *base, HnswElement element, int m, HnswAllocator * alloc);
-bool		HnswInsertTupleOnDisk(Relation index, HnswSupport * support, Datum value, ItemPointer heaptid, bool building);
-void		HnswUpdateNeighborsOnDisk(Relation index, HnswSupport * support, HnswElement e, int m, bool checkExisting, bool building);
+bool		HnswInsertTupleOnDisk(Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, void * metastate, Datum value, ItemPointer heaptid, bool building);
+void		HnswUpdateNeighborsOnDisk(Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, HnswElement e, int m, bool checkExisting, bool building, bool neighborMetadata);
 void		HnswLoadElementFromTuple(HnswElement element, HnswElementTuple etup, bool loadHeaptids, bool loadVec);
 void		HnswLoadElement(HnswElement element, double *distance, HnswQuery * q, Relation index, HnswSupport * support, bool loadVec, double *maxDistance);
 bool		HnswFormIndexValue(Datum *out, Datum *values, bool *isnull, const HnswTypeInfo * typeInfo, HnswSupport * support);
 void		HnswSetElementTuple(char *base, HnswElementTuple etup, HnswElement element);
 void		HnswUpdateConnection(char *base, HnswNeighborArray * neighbors, HnswElement newElement, float distance, int lm, int *updateIdx, Relation index, HnswSupport * support);
-bool		HnswLoadNeighborTids(HnswElement element, ItemPointerData *indextids, Relation index, int m, int lm, int lc);
+bool		HnswLoadNeighborEntries(HnswElement element, HnswNeighborEntryData *entries, Relation index, const HnswTypeInfo * typeInfo, int m, int lm, int lc, bool neighborMetadata);
 void		HnswInitLockTranche(void);
 const		HnswTypeInfo *HnswGetTypeInfo(Relation index);
 PGDLLEXPORT void HnswParallelBuildMain(dsm_segment *seg, shm_toc *toc);
diff --git a/src/hnswbuild.c b/src/hnswbuild.c
index b667478..bfb77d6 100644
--- a/src/hnswbuild.c
+++ b/src/hnswbuild.c
@@ -47,6 +47,7 @@
 #include "catalog/pg_type_d.h"
 #include "commands/progress.h"
 #include "hnsw.h"
+#include "hnswmeta.h"
 #include "miscadmin.h"
 #include "optimizer/optimizer.h"
 #include "storage/bufmgr.h"
@@ -65,9 +66,10 @@
 #include "utils/wait_event.h"
 #endif
 
-#define PARALLEL_KEY_HNSW_SHARED		UINT64CONST(0xA000000000000001)
-#define PARALLEL_KEY_HNSW_AREA			UINT64CONST(0xA000000000000002)
-#define PARALLEL_KEY_QUERY_TEXT			UINT64CONST(0xA000000000000003)
+#define PARALLEL_KEY_HNSW_SHARED			UINT64CONST(0xA000000000000001)
+#define PARALLEL_KEY_HNSW_AREA				UINT64CONST(0xA000000000000002)
+#define PARALLEL_KEY_QUERY_TEXT				UINT64CONST(0xA000000000000003)
+#define PARALLEL_KEY_HNSW_NEIGHBOR_METADATA	UINT64CONST(0xA000000000000004)
 
 /*
  * Create the metapage
@@ -99,6 +101,33 @@ CreateMetaPage(HnswBuildState * buildstate)
 	((PageHeader) page)->pd_lower =
 		((char *) metap + sizeof(HnswMetaPageData)) - (char *) page;
 
+	/* Set neighbor metadata information */
+	if (buildstate->neighborMetadataState != NULL)
+	{
+		HnswNeighborMetadataState *metastate = (HnswNeighborMetadataState *) buildstate->neighborMetadataState;
+		metap->hasNeighborMetadata = true;
+		metap->pqSubvectorDim = metastate->subvectorDim;
+		metap->pqM = metastate->m;
+
+		/* Create centroid pages and record start page number */
+		metap->neighborMetadataStartBlkno = HnswCreateCodebookPages(buildstate, metastate, &metap->neighborMetadataPageCount);
+
+		/* Calculate head page position after metadata pages */
+		metap->headBlkno = metap->neighborMetadataStartBlkno + metap->neighborMetadataPageCount;
+	}
+	else
+	{
+		metap->hasNeighborMetadata = false;
+		metap->neighborMetadataStartBlkno = InvalidBlockNumber;
+		metap->neighborMetadataPageCount = 0;
+		metap->pqSubvectorDim = 0;
+		metap->pqM = 0;
+
+		/* Use traditional head page position */
+		metap->headBlkno = HNSW_HEAD_BLKNO;
+	}
+
+
 	MarkBufferDirty(buf);
 	UnlockReleaseBuffer(buf);
 }
@@ -139,6 +168,8 @@ CreateGraphPages(HnswBuildState * buildstate)
 {
 	Relation	index = buildstate->index;
 	ForkNumber	forkNum = buildstate->forkNum;
+	bool		neighborMetadata = buildstate->neighborMetadata;
+	const		HnswTypeInfo *typeInfo = buildstate->typeInfo;
 	Size		maxSize;
 	HnswElementTuple etup;
 	HnswNeighborTuple ntup;
@@ -177,7 +208,7 @@ CreateGraphPages(HnswBuildState * buildstate)
 
 		/* Calculate sizes */
 		etupSize = HNSW_ELEMENT_TUPLE_SIZE(VARSIZE_ANY(valuePtr));
-		ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(element->level, buildstate->m);
+		ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(element->level, buildstate->m, typeInfo, neighborMetadata);
 		combinedSize = etupSize + ntupSize + sizeof(ItemIdData);
 
 		/* Initial size check */
@@ -242,6 +273,9 @@ WriteNeighborTuples(HnswBuildState * buildstate)
 {
 	Relation	index = buildstate->index;
 	ForkNumber	forkNum = buildstate->forkNum;
+	bool		neighborMetadata = buildstate->neighborMetadata;
+	const		HnswTypeInfo *typeInfo = buildstate->typeInfo;
+	HnswSupport *support = &buildstate->support;
 	int			m = buildstate->m;
 	HnswElementPtr iter = buildstate->graph->head;
 	char	   *base = buildstate->hnswarea;
@@ -255,7 +289,7 @@ WriteNeighborTuples(HnswBuildState * buildstate)
 		HnswElement element = HnswPtrAccess(base, iter);
 		Buffer		buf;
 		Page		page;
-		Size		ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(element->level, m);
+		Size		ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(element->level, m, typeInfo, neighborMetadata);
 
 		/* Update iterator */
 		iter = element->next;
@@ -271,7 +305,7 @@ WriteNeighborTuples(HnswBuildState * buildstate)
 		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
 		page = BufferGetPage(buf);
 
-		HnswSetNeighborTuple(base, ntup, element, m);
+		HnswSetNeighborTuple(base, ntup, element, m, typeInfo, support, buildstate->neighborMetadataState, neighborMetadata);
 
 		if (!PageIndexTupleOverwrite(page, element->neighborOffno, (Item) ntup, ntupSize))
 			elog(ERROR, "failed to add index item to \"%s\"", RelationGetRelationName(index));
@@ -425,6 +459,7 @@ static void
 InsertTupleInMemory(HnswBuildState * buildstate, HnswElement element)
 {
 	HnswGraph  *graph = buildstate->graph;
+	const		HnswTypeInfo *typeInfo = buildstate->typeInfo;
 	HnswSupport *support = &buildstate->support;
 	HnswElement entryPoint;
 	LWLock	   *entryLock = &graph->entryLock;
@@ -457,7 +492,7 @@ InsertTupleInMemory(HnswBuildState * buildstate, HnswElement element)
 	}
 
 	/* Find neighbors for element */
-	HnswFindElementNeighbors(base, element, entryPoint, NULL, support, m, efConstruction, false);
+	HnswFindElementNeighbors(base, element, entryPoint, NULL, typeInfo, support, m, efConstruction, false);
 
 	/* Update graph in memory */
 	UpdateGraphInMemory(support, element, m, efConstruction, entryPoint, buildstate);
@@ -497,7 +532,7 @@ InsertTuple(Relation index, Datum *values, bool *isnull, ItemPointer heaptid, Hn
 	{
 		LWLockRelease(flushLock);
 
-		return HnswInsertTupleOnDisk(index, support, value, heaptid, true);
+		return HnswInsertTupleOnDisk(index, buildstate->typeInfo, support, buildstate->neighborMetadataState, value, heaptid, true);
 	}
 
 	/*
@@ -529,7 +564,7 @@ InsertTuple(Relation index, Datum *values, bool *isnull, ItemPointer heaptid, Hn
 
 		LWLockRelease(flushLock);
 
-		return HnswInsertTupleOnDisk(index, support, value, heaptid, true);
+		return HnswInsertTupleOnDisk(index, buildstate->typeInfo, support, buildstate->neighborMetadataState, value, heaptid, true);
 	}
 
 	/* Ok, we can proceed to allocate the element */
@@ -664,6 +699,7 @@ InitBuildState(HnswBuildState * buildstate, Relation heap, Relation index, Index
 
 	buildstate->m = HnswGetM(index);
 	buildstate->efConstruction = HnswGetEfConstruction(index);
+	buildstate->neighborMetadata = HnswSupportNeighborMetadata(index);
 	buildstate->dimensions = TupleDescAttr(index->rd_att, 0)->atttypmod;
 
 	/* Disallow varbit since require fixed dimensions */
@@ -699,6 +735,14 @@ InitBuildState(HnswBuildState * buildstate, Relation heap, Relation index, Index
 	buildstate->ml = HnswGetMl(buildstate->m);
 	buildstate->maxLevel = HnswGetMaxLevel(buildstate->m);
 
+	if (buildstate->neighborMetadata && buildstate->typeInfo->neighborMetadataBytes > 0)
+		HnswInitNeighborMetadataState(index, buildstate);
+	else
+		buildstate->neighborMetadataState = NULL;
+
+	buildstate->kmeansnormprocinfo = NULL;
+	buildstate->collation = InvalidOid;
+
 	buildstate->graphCtx = GenerationContextCreate(CurrentMemoryContext,
 												   "Hnsw build graph context",
 #if PG_VERSION_NUM >= 150000
@@ -722,6 +766,9 @@ InitBuildState(HnswBuildState * buildstate, Relation heap, Relation index, Index
 static void
 FreeBuildState(HnswBuildState * buildstate)
 {
+	if (buildstate->neighborMetadataState)
+		HnswFreeNeighborMetadataState(buildstate->neighborMetadataState);
+
 	MemoryContextDelete(buildstate->graphCtx);
 	MemoryContextDelete(buildstate->tmpCtx);
 }
@@ -763,7 +810,7 @@ ParallelHeapScan(HnswBuildState * buildstate)
  * Perform a worker's portion of a parallel insert
  */
 static void
-HnswParallelScanAndInsert(Relation heapRel, Relation indexRel, HnswShared * hnswshared, char *hnswarea, bool progress)
+HnswParallelScanAndInsert(Relation heapRel, Relation indexRel, HnswShared * hnswshared, char *hnswarea, shm_toc *toc, bool progress)
 {
 	HnswBuildState buildstate;
 	TableScanDesc scan;
@@ -776,6 +823,18 @@ HnswParallelScanAndInsert(Relation heapRel, Relation indexRel, HnswShared * hnsw
 	InitBuildState(&buildstate, heapRel, indexRel, indexInfo, MAIN_FORKNUM);
 	buildstate.graph = &hnswshared->graphData;
 	buildstate.hnswarea = hnswarea;
+
+	/* Restore neighbor metadata from shared memory if present */
+	if (hnswshared->hasNeighborMetadata)
+	{
+		char *sharedmeta = shm_toc_lookup(toc, PARALLEL_KEY_HNSW_NEIGHBOR_METADATA, false);
+		buildstate.neighborMetadataState = HnswLoadNeighborMetadataStateFromShm(sharedmeta, buildstate.typeInfo);
+	}
+	else
+	{
+		buildstate.neighborMetadataState = NULL;
+	}
+
 	InitAllocator(&buildstate.allocator, &HnswSharedMemoryAlloc, &buildstate);
 	scan = table_beginscan_parallel(heapRel,
 									ParallelTableScanFromHnswShared(hnswshared));
@@ -844,7 +903,7 @@ HnswParallelBuildMain(dsm_segment *seg, shm_toc *toc)
 	hnswarea = shm_toc_lookup(toc, PARALLEL_KEY_HNSW_AREA, false);
 
 	/* Perform inserts */
-	HnswParallelScanAndInsert(heapRel, indexRel, hnswshared, hnswarea, false);
+	HnswParallelScanAndInsert(heapRel, indexRel, hnswshared, hnswarea, toc, false);
 
 	/* Close relations within worker */
 	index_close(indexRel, indexLockmode);
@@ -871,9 +930,14 @@ HnswEndParallel(HnswLeader * hnswleader)
  * Return size of shared memory required for parallel index build
  */
 static Size
-ParallelEstimateShared(Relation heap, Snapshot snapshot)
+ParallelEstimateShared(Relation heap, Snapshot snapshot, Relation index, void * metastate)
 {
-	return add_size(BUFFERALIGN(sizeof(HnswShared)), table_parallelscan_estimate(heap, snapshot));
+	Size		size;
+
+	size = BUFFERALIGN(sizeof(HnswShared));
+	size = add_size(size, table_parallelscan_estimate(heap, snapshot));
+
+	return size;
 }
 
 /*
@@ -885,7 +949,7 @@ HnswLeaderParticipateAsWorker(HnswBuildState * buildstate)
 	HnswLeader *hnswleader = buildstate->hnswleader;
 
 	/* Perform work common to all participants */
-	HnswParallelScanAndInsert(buildstate->heap, buildstate->index, hnswleader->hnswshared, hnswleader->hnswarea, true);
+	HnswParallelScanAndInsert(buildstate->heap, buildstate->index, hnswleader->hnswshared, hnswleader->hnswarea, hnswleader->pcxt->toc, true);
 }
 
 /*
@@ -898,6 +962,7 @@ HnswBeginParallel(HnswBuildState * buildstate, bool isconcurrent, int request)
 	Snapshot	snapshot;
 	Size		esthnswshared;
 	Size		esthnswarea;
+	Size		estmeta;
 	Size		estother;
 	HnswShared *hnswshared;
 	char	   *hnswarea;
@@ -921,9 +986,14 @@ HnswBeginParallel(HnswBuildState * buildstate, bool isconcurrent, int request)
 		snapshot = RegisterSnapshot(GetTransactionSnapshot());
 
 	/* Estimate size of workspaces */
-	esthnswshared = ParallelEstimateShared(buildstate->heap, snapshot);
+	esthnswshared = ParallelEstimateShared(buildstate->heap, snapshot, buildstate->index, buildstate->neighborMetadataState);
 	shm_toc_estimate_chunk(&pcxt->estimator, esthnswshared);
 
+	/* Estimate metadata state size */
+	estmeta = HnswEstimateSharedNeighborMetadataState(buildstate->neighborMetadataState);
+	if (estmeta > 0)
+		shm_toc_estimate_chunk(&pcxt->estimator, estmeta);
+
 	/* Leave space for other objects in shared memory */
 	/* Docker has a default limit of 64 MB for shm_size */
 	/* which happens to be the default value of maintenance_work_mem */
@@ -933,7 +1003,7 @@ HnswBeginParallel(HnswBuildState * buildstate, bool isconcurrent, int request)
 		esthnswarea -= estother;
 
 	shm_toc_estimate_chunk(&pcxt->estimator, esthnswarea);
-	shm_toc_estimate_keys(&pcxt->estimator, 2);
+	shm_toc_estimate_keys(&pcxt->estimator, 2 + (estmeta > 0 ? 1 : 0));
 
 	/* Finally, estimate PARALLEL_KEY_QUERY_TEXT space */
 	if (debug_query_string)
@@ -964,6 +1034,22 @@ HnswBeginParallel(HnswBuildState * buildstate, bool isconcurrent, int request)
 	hnswshared->heaprelid = RelationGetRelid(buildstate->heap);
 	hnswshared->indexrelid = RelationGetRelid(buildstate->index);
 	hnswshared->isconcurrent = isconcurrent;
+
+	/* Store metadata state in shared memory if present */
+	if (buildstate->neighborMetadataState != NULL && estmeta > 0)
+	{
+		/* Copy metadata state to shared memory */
+		char *sharedmeta = HnswCopyNeighborMetadataStateToShm(pcxt, (HnswNeighborMetadataState *) buildstate->neighborMetadataState, estmeta);
+
+		/* Register in shared memory */
+		shm_toc_insert(pcxt->toc, PARALLEL_KEY_HNSW_NEIGHBOR_METADATA, sharedmeta);
+		hnswshared->hasNeighborMetadata = true;
+	}
+	else
+	{
+		hnswshared->hasNeighborMetadata = false;
+	}
+
 	ConditionVariableInit(&hnswshared->workersdonecv);
 	SpinLockInit(&hnswshared->mutex);
 	/* Initialize mutable state */
diff --git a/src/hnswinsert.c b/src/hnswinsert.c
index a5fac4e..19b16e4 100644
--- a/src/hnswinsert.c
+++ b/src/hnswinsert.c
@@ -4,6 +4,7 @@
 
 #include "access/generic_xlog.h"
 #include "hnsw.h"
+#include "hnswmeta.h"
 #include "storage/bufmgr.h"
 #include "storage/lmgr.h"
 #include "utils/datum.h"
@@ -136,7 +137,7 @@ HnswInsertAppendPage(Relation index, Buffer *nbuf, Page *npage, GenericXLogState
  * Add to element and neighbor pages
  */
 static void
-AddElementOnDisk(Relation index, HnswElement e, int m, BlockNumber insertPage, BlockNumber *updatedInsertPage, bool building)
+AddElementOnDisk(Relation index, const HnswTypeInfo * typeInfo, HnswSupport *support, void * metastate, HnswElement e, int m, BlockNumber insertPage, BlockNumber *updatedInsertPage, bool building, bool neighborMetadata)
 {
 	Buffer		buf;
 	Page		page;
@@ -159,10 +160,10 @@ AddElementOnDisk(Relation index, HnswElement e, int m, BlockNumber insertPage, B
 
 	/* Calculate sizes */
 	etupSize = HNSW_ELEMENT_TUPLE_SIZE(VARSIZE_ANY(HnswPtrAccess(base, e->value)));
-	ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(e->level, m);
+	ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(e->level, m, typeInfo, neighborMetadata);
 	combinedSize = etupSize + ntupSize + sizeof(ItemIdData);
 	maxSize = HNSW_MAX_SIZE;
-	minCombinedSize = etupSize + HNSW_NEIGHBOR_TUPLE_SIZE(0, m) + sizeof(ItemIdData);
+	minCombinedSize = etupSize + HNSW_NEIGHBOR_TUPLE_SIZE(0, m, typeInfo, neighborMetadata) + sizeof(ItemIdData);
 
 	/* Prepare element tuple */
 	etup = palloc0(etupSize);
@@ -170,7 +171,7 @@ AddElementOnDisk(Relation index, HnswElement e, int m, BlockNumber insertPage, B
 
 	/* Prepare neighbor tuple */
 	ntup = palloc0(ntupSize);
-	HnswSetNeighborTuple(base, ntup, e, m);
+	HnswSetNeighborTuple(base, ntup, e, m, typeInfo, support, metastate, neighborMetadata);
 
 	/* Find a page (or two if needed) to insert the tuples */
 	for (;;)
@@ -344,18 +345,18 @@ AddElementOnDisk(Relation index, HnswElement e, int m, BlockNumber insertPage, B
  * Load neighbors
  */
 static HnswNeighborArray *
-HnswLoadNeighbors(HnswElement element, Relation index, int m, int lm, int lc)
+HnswLoadNeighbors(HnswElement element, Relation index, const HnswTypeInfo * typeInfo, int m, int lm, int lc, bool neighborMetadata)
 {
 	char	   *base = NULL;
 	HnswNeighborArray *neighbors = HnswInitNeighborArray(lm, NULL);
-	ItemPointerData indextids[HNSW_MAX_M * 2];
+	HnswNeighborEntryData entries[HNSW_MAX_M * 2];
 
-	if (!HnswLoadNeighborTids(element, indextids, index, m, lm, lc))
+	if (!HnswLoadNeighborEntries(element, entries, index, typeInfo, m, lm, lc, neighborMetadata))
 		return neighbors;
 
 	for (int i = 0; i < lm; i++)
 	{
-		ItemPointer indextid = &indextids[i];
+		ItemPointer indextid = &entries[i].indextid;
 		HnswElement e;
 		HnswCandidate *hc;
 
@@ -400,7 +401,7 @@ LoadElementsForInsert(HnswNeighborArray * neighbors, HnswQuery * q, int *idx, Re
  * Get update index
  */
 static int
-GetUpdateIndex(HnswElement element, HnswElement newElement, float distance, int m, int lm, int lc, Relation index, HnswSupport * support, MemoryContext updateCtx)
+GetUpdateIndex(HnswElement element, HnswElement newElement, float distance, int m, int lm, int lc, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, MemoryContext updateCtx, bool neighborMetadata)
 {
 	char	   *base = NULL;
 	int			idx = -1;
@@ -412,7 +413,7 @@ GetUpdateIndex(HnswElement element, HnswElement newElement, float distance, int
 	 * selecting neighbors can take time. Could use optimistic locking to
 	 * retry if another update occurs before getting exclusive lock.
 	 */
-	neighbors = HnswLoadNeighbors(element, index, m, lm, lc);
+	neighbors = HnswLoadNeighbors(element, index, typeInfo, m, lm, lc, neighborMetadata);
 
 	/*
 	 * Could improve performance for vacuuming by checking neighbors against
@@ -445,11 +446,11 @@ GetUpdateIndex(HnswElement element, HnswElement newElement, float distance, int
  * Check if connection already exists
  */
 static bool
-ConnectionExists(HnswElement e, HnswNeighborTuple ntup, int startIdx, int lm)
+ConnectionExists(HnswElement e, HnswNeighborTuple ntup, const HnswTypeInfo * typeInfo, int startIdx, int lm, bool neighborMetadata)
 {
 	for (int i = 0; i < lm; i++)
 	{
-		ItemPointer indextid = &ntup->indextids[startIdx + i];
+		ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, startIdx + i, typeInfo, neighborMetadata);
 
 		if (!ItemPointerIsValid(indextid))
 			break;
@@ -465,7 +466,7 @@ ConnectionExists(HnswElement e, HnswNeighborTuple ntup, int startIdx, int lm)
  * Update neighbor
  */
 static void
-UpdateNeighborOnDisk(HnswElement element, HnswElement newElement, int idx, int m, int lm, int lc, Relation index, bool checkExisting, bool building)
+UpdateNeighborOnDisk(HnswElement element, HnswElement newElement, int idx, int m, int lm, int lc, Relation index, const HnswTypeInfo * typeInfo, bool checkExisting, bool building, bool neighborMetadata)
 {
 	Buffer		buf;
 	Page		page;
@@ -495,7 +496,7 @@ UpdateNeighborOnDisk(HnswElement element, HnswElement newElement, int idx, int m
 	startIdx = (element->level - lc) * m;
 
 	/* Check for existing connection */
-	if (checkExisting && ConnectionExists(newElement, ntup, startIdx, lm))
+	if (checkExisting && ConnectionExists(newElement, ntup, typeInfo, startIdx, lm, neighborMetadata))
 		idx = -1;
 	else if (idx == -2)
 	{
@@ -503,7 +504,9 @@ UpdateNeighborOnDisk(HnswElement element, HnswElement newElement, int idx, int m
 		/* TODO Retry updating connections if not */
 		for (int j = 0; j < lm; j++)
 		{
-			if (!ItemPointerIsValid(&ntup->indextids[startIdx + j]))
+			ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, startIdx + j, typeInfo, neighborMetadata);
+
+			if (!ItemPointerIsValid(indextid))
 			{
 				idx = startIdx + j;
 				break;
@@ -516,7 +519,7 @@ UpdateNeighborOnDisk(HnswElement element, HnswElement newElement, int idx, int m
 	/* Make robust to issues */
 	if (idx >= 0 && idx < ntup->count)
 	{
-		ItemPointer indextid = &ntup->indextids[idx];
+		ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, idx, typeInfo, neighborMetadata);
 
 		/* Update neighbor on the buffer */
 		ItemPointerSet(indextid, newElement->blkno, newElement->offno);
@@ -537,7 +540,7 @@ UpdateNeighborOnDisk(HnswElement element, HnswElement newElement, int idx, int m
  * Update neighbors
  */
 void
-HnswUpdateNeighborsOnDisk(Relation index, HnswSupport * support, HnswElement e, int m, bool checkExisting, bool building)
+HnswUpdateNeighborsOnDisk(Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, HnswElement e, int m, bool checkExisting, bool building, bool neighborMetadata)
 {
 	char	   *base = NULL;
 
@@ -560,13 +563,13 @@ HnswUpdateNeighborsOnDisk(Relation index, HnswSupport * support, HnswElement e,
 			HnswElement neighborElement = HnswPtrAccess(base, hc->element);
 			int			idx;
 
-			idx = GetUpdateIndex(neighborElement, e, hc->distance, m, lm, lc, index, support, updateCtx);
+			idx = GetUpdateIndex(neighborElement, e, hc->distance, m, lm, lc, index, typeInfo, support, updateCtx, neighborMetadata);
 
 			/* New element was not selected as a neighbor */
 			if (idx == -1)
 				continue;
 
-			UpdateNeighborOnDisk(neighborElement, e, idx, m, lm, lc, index, checkExisting, building);
+			UpdateNeighborOnDisk(neighborElement, e, idx, m, lm, lc, index, typeInfo, checkExisting, building, neighborMetadata);
 		}
 	}
 
@@ -660,7 +663,7 @@ FindDuplicateOnDisk(Relation index, HnswElement element, bool building)
  * Update graph on disk
  */
 static void
-UpdateGraphOnDisk(Relation index, HnswSupport * support, HnswElement element, int m, int efConstruction, HnswElement entryPoint, bool building)
+UpdateGraphOnDisk(Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, void * metastate, HnswElement element, int m, int efConstruction, HnswElement entryPoint, bool building, bool neighborMetadata)
 {
 	BlockNumber newInsertPage = InvalidBlockNumber;
 
@@ -669,14 +672,14 @@ UpdateGraphOnDisk(Relation index, HnswSupport * support, HnswElement element, in
 		return;
 
 	/* Add element */
-	AddElementOnDisk(index, element, m, GetInsertPage(index), &newInsertPage, building);
+	AddElementOnDisk(index, typeInfo, support, metastate, element, m, GetInsertPage(index), &newInsertPage, building, neighborMetadata);
 
 	/* Update insert page if needed */
 	if (BlockNumberIsValid(newInsertPage))
 		HnswUpdateMetaPage(index, 0, NULL, newInsertPage, MAIN_FORKNUM, building);
 
 	/* Update neighbors */
-	HnswUpdateNeighborsOnDisk(index, support, element, m, false, building);
+	HnswUpdateNeighborsOnDisk(index, typeInfo, support, element, m, false, building, neighborMetadata);
 
 	/* Update entry point if needed */
 	if (entryPoint == NULL || element->level > entryPoint->level)
@@ -687,12 +690,13 @@ UpdateGraphOnDisk(Relation index, HnswSupport * support, HnswElement element, in
  * Insert a tuple into the index
  */
 bool
-HnswInsertTupleOnDisk(Relation index, HnswSupport * support, Datum value, ItemPointer heaptid, bool building)
+HnswInsertTupleOnDisk(Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, void * metastate, Datum value, ItemPointer heaptid, bool building)
 {
 	HnswElement entryPoint;
 	HnswElement element;
 	int			m;
 	int			efConstruction = HnswGetEfConstruction(index);
+	bool		neighborMetadata = HnswSupportNeighborMetadata(index);
 	LOCKMODE	lockmode = ShareLock;
 	char	   *base = NULL;
 
@@ -725,10 +729,10 @@ HnswInsertTupleOnDisk(Relation index, HnswSupport * support, Datum value, ItemPo
 	}
 
 	/* Find neighbors for element */
-	HnswFindElementNeighbors(base, element, entryPoint, index, support, m, efConstruction, false);
+	HnswFindElementNeighbors(base, element, entryPoint, index, typeInfo, support, m, efConstruction, false);
 
 	/* Update graph on disk */
-	UpdateGraphOnDisk(index, support, element, m, efConstruction, entryPoint, building);
+	UpdateGraphOnDisk(index, typeInfo, support, metastate, element, m, efConstruction, entryPoint, building, neighborMetadata);
 
 	/* Release lock */
 	UnlockPage(index, HNSW_UPDATE_LOCK, lockmode);
@@ -740,7 +744,7 @@ HnswInsertTupleOnDisk(Relation index, HnswSupport * support, Datum value, ItemPo
  * Insert a tuple into the index
  */
 static void
-HnswInsertTuple(Relation index, Datum *values, bool *isnull, ItemPointer heaptid)
+HnswInsertTuple(Relation index, void * metastate, Datum *values, bool *isnull, ItemPointer heaptid)
 {
 	Datum		value;
 	const		HnswTypeInfo *typeInfo = HnswGetTypeInfo(index);
@@ -752,7 +756,7 @@ HnswInsertTuple(Relation index, Datum *values, bool *isnull, ItemPointer heaptid
 	if (!HnswFormIndexValue(&value, values, isnull, typeInfo, &support))
 		return;
 
-	HnswInsertTupleOnDisk(index, &support, value, heaptid, false);
+	HnswInsertTupleOnDisk(index, typeInfo, &support, metastate, value, heaptid, false);
 }
 
 /*
@@ -769,6 +773,7 @@ hnswinsert(Relation index, Datum *values, bool *isnull, ItemPointer heap_tid,
 {
 	MemoryContext oldCtx;
 	MemoryContext insertCtx;
+	void		  *metastate;
 
 	/* Skip nulls */
 	if (isnull[0])
@@ -780,8 +785,11 @@ hnswinsert(Relation index, Datum *values, bool *isnull, ItemPointer heap_tid,
 									  ALLOCSET_DEFAULT_SIZES);
 	oldCtx = MemoryContextSwitchTo(insertCtx);
 
+	/* Load neighbor metadata state */
+	metastate = HnswLoadNeighborMetadataStateFromDisk(index);
+
 	/* Insert tuple */
-	HnswInsertTuple(index, values, isnull, heap_tid);
+	HnswInsertTuple(index, metastate, values, isnull, heap_tid);
 
 	/* Delete memory context */
 	MemoryContextSwitchTo(oldCtx);
diff --git a/src/hnswmeta.c b/src/hnswmeta.c
new file mode 100644
index 0000000..212c60f
--- /dev/null
+++ b/src/hnswmeta.c
@@ -0,0 +1,785 @@
+#include "postgres.h"
+
+#include <float.h>
+#include <math.h>
+
+#include "access/table.h"
+#include "access/tableam.h"
+#include "catalog/index.h"
+#include "catalog/pg_proc.h"
+#include "hnsw.h"
+#include "hnswmeta.h"
+#include "storage/bufmgr.h"
+#include "utils/float.h"
+#include "utils/datum.h"
+#include "utils/memutils.h"
+#include "utils/rel.h"
+#include "utils/syscache.h"
+
+/*
+ * Get whether neighbor metadata is stored in the index
+ */
+static bool
+HnswGetNeighborMetadata(Relation index)
+{
+	HnswOptions	   *opts = (HnswOptions *) index->rd_options;
+
+	if (opts)
+		return opts->neighborMetadata;
+
+	return HNSW_DEFAULT_NEIGHBOR_METADATA;
+}
+
+/*
+ * Check if neighbor metadata is supported
+ */
+bool
+HnswSupportNeighborMetadata(Relation index)
+{
+	/* Force disable if the indexed data type does not support metadata */
+	const HnswTypeInfo *typeInfo = HnswGetTypeInfo(index);
+	return HnswGetNeighborMetadata(index) && typeInfo->neighborMetadataBytes > 0;
+}
+
+
+static bool
+CheckSupportFunctionName(FmgrInfo *distanceProcinfo, const char *targetFuncname)
+{
+	Oid				funcoid = distanceProcinfo->fn_oid;
+	HeapTuple 		proctup;
+	Form_pg_proc 	procform;
+	char 		   *funcname = NULL;
+	bool			result = false;
+
+	proctup = SearchSysCache1(PROCOID, ObjectIdGetDatum(funcoid));
+	if (!HeapTupleIsValid(proctup))
+		return false;
+
+	procform = (Form_pg_proc) GETSTRUCT(proctup);
+	funcname = NameStr(procform->proname);
+
+	result = strcmp(funcname, targetFuncname) == 0;
+
+	ReleaseSysCache(proctup);
+
+	return result;
+}
+
+/*
+ * TODO Smarter way to handle distance-specific optimization?
+ */
+bool
+HnswIsVectorL2Distance(FmgrInfo * distanceProcinfo)
+{
+	/*
+	 * vector_l2_ops uses vector_l2_squared_distance() as a distance function as follows:
+	 *
+	 * CREATE OPERATOR CLASS vector_l2_ops
+	 * 	DEFAULT FOR TYPE vector USING ivfflat AS
+	 * 	OPERATOR 1 <-> (vector, vector) FOR ORDER BY float_ops,
+	 * 	FUNCTION 1 vector_l2_squared_distance(vector, vector),
+	 * 	FUNCTION 3 l2_distance(vector, vector);
+	 */
+	return CheckSupportFunctionName(distanceProcinfo, "vector_l2_squared_distance");
+}
+
+/*
+ * Get the size of a vector item (Copied from ivfutils.c#VectorItemSize)
+ */
+Size
+HnswVectorItemSize(int dimensions)
+{
+	return VECTOR_SIZE(dimensions);
+}
+
+/*
+ * Update center vector from sum vector (Copied from ivfutils.c#VectorUpdateCenter)
+ */
+void
+HnswVectorUpdateCenter(Pointer v, int dimensions, float *x)
+{
+	Vector	   *vec = (Vector *) v;
+
+	SET_VARSIZE(vec, VECTOR_SIZE(dimensions));
+	vec->dim = dimensions;
+
+	for (int k = 0; k < dimensions; k++)
+		vec->x[k] = x[k];
+}
+
+/*
+ * Sum vector into x (Copied from ivfutils.c#VectorSumCenter)
+ */
+void
+HnswVectorSumCenter(Pointer v, float *x)
+{
+	Vector	   *vec = (Vector *) v;
+
+	for (int k = 0; k < vec->dim; k++)
+		x[k] += vec->x[k];
+}
+
+/*
+ * Load centroid data from pages
+ */
+static void
+LoadCentroidsFromPages(Relation index, BlockNumber startBlkno, uint16 pageCount, HnswNeighborMetadataState * metastate)
+{
+	for (uint16 p = 0; p < pageCount; p++)
+	{
+		Buffer buf = ReadBuffer(index, startBlkno + p);
+		LockBuffer(buf, BUFFER_LOCK_SHARE);
+		Page page = BufferGetPage(buf);
+
+		OffsetNumber maxoff = PageGetMaxOffsetNumber(page);
+		for (OffsetNumber offno = FirstOffsetNumber; offno <= maxoff; offno = OffsetNumberNext(offno))
+		{
+			ItemId				iid = PageGetItemId(page, offno);
+			HnswCentroidTuple 	ctup = (HnswCentroidTuple) PageGetItem(page, iid);
+
+			if (ctup->type == HNSW_CENTROID_TUPLE_TYPE)
+			{
+				/* Store centroid data in VectorArray */
+				VectorArray subvectorCentroids = metastate->centroids[ctup->subvectorIndex];
+				Vector *centroid = (Vector *) VectorArrayGet(subvectorCentroids, ctup->centroidIndex);
+				memcpy(centroid, &ctup->data, VECTOR_SIZE(ctup->dimensions));
+			}
+		}
+
+		UnlockReleaseBuffer(buf);
+	}
+}
+
+/*
+ * Calculate optimal PQ subvector dimension based on vector dimensions
+ * and metadata size constraints
+ */
+static int
+CalculateOptimalPQSubvectorDim(int dimensions)
+{
+	int			minSubvectorDim = 4;
+	int			maxPossibleSubvectors = Min(dimensions / minSubvectorDim, HNSW_NEIGHBOR_VECTOR_L2_METADATA_BYTES);
+	int			preferredSubvectors[] = {2, 4, 6, 8, 10, 12, 14, 16};
+	int			numPreferred = sizeof(preferredSubvectors) / sizeof(preferredSubvectors[0]);
+
+	/* Ensure we can have at least 2 subvectors */
+	if (maxPossibleSubvectors < 2)
+		return (dimensions + 1) / 2;
+
+	/* Try to find optimal subvector count, checking clean division first */
+	for (int i = numPreferred - 1; i >= 0; i--)
+	{
+		int			candidateM = preferredSubvectors[i];
+		int			resultingSubvectorDim;
+
+		if (candidateM > maxPossibleSubvectors)
+			continue;
+
+		/* Prefer clean division if possible */
+		if (dimensions % candidateM == 0)
+			return dimensions / candidateM;
+
+		/* Otherwise check if minimum dimension constraint is met with padding */
+		resultingSubvectorDim = (dimensions + candidateM - 1) / candidateM;
+		if (resultingSubvectorDim >= minSubvectorDim)
+			return resultingSubvectorDim;
+	}
+
+	/* Final fallback: ensure minimum subvector dimension */
+	return Max(minSubvectorDim, (dimensions + maxPossibleSubvectors - 1) / maxPossibleSubvectors);
+}
+
+/*
+ * Check if non-zero norm (Copied from ivfutils.c#IvfflatCheckNorm())
+ */
+static bool
+CheckNorm(FmgrInfo *procinfo, Oid collation, Datum value)
+{
+	return DatumGetFloat8(FunctionCall1Coll(procinfo, collation, value)) > 0;
+}
+
+/*
+ * Normalize value (Copied from ivfbuild.c#IvfflatNormValue())
+ */
+static Datum
+NormValue(const HnswTypeInfo * typeInfo, Oid collation, Datum value)
+{
+	return DirectFunctionCall1Coll(typeInfo->normalize, collation, value);
+}
+
+/*
+ * Add sample (Copied from ivfbuild.c#AddSample())
+ */
+static void
+AddSample(Datum *values, HnswBuildState * buildstate)
+{
+	VectorArray samples = buildstate->samples;
+	int			targsamples = samples->maxlen;
+
+	/* Detoast once for all calls */
+	Datum		value = PointerGetDatum(PG_DETOAST_DATUM(values[0]));
+
+	/*
+	 * Normalize with KMEANS_NORM_PROC since spherical distance function
+	 * expects unit vectors
+	 */
+	if (buildstate->kmeansnormprocinfo != NULL)
+	{
+		if (!CheckNorm(buildstate->kmeansnormprocinfo, buildstate->collation, value))
+			return;
+
+		value = NormValue(buildstate->typeInfo, buildstate->collation, value);
+	}
+
+	if (samples->length < targsamples)
+	{
+		VectorArraySet(samples, samples->length, DatumGetPointer(value));
+		samples->length++;
+	}
+	else
+	{
+		if (buildstate->rowstoskip < 0)
+			buildstate->rowstoskip = reservoir_get_next_S(&buildstate->rstate, samples->length, targsamples);
+
+		if (buildstate->rowstoskip <= 0)
+		{
+#if PG_VERSION_NUM >= 150000
+			int			k = (int) (targsamples * sampler_random_fract(&buildstate->rstate.randstate));
+#else
+			int			k = (int) (targsamples * sampler_random_fract(buildstate->rstate.randstate));
+#endif
+
+			Assert(k >= 0 && k < targsamples);
+			VectorArraySet(samples, k, DatumGetPointer(value));
+		}
+
+		buildstate->rowstoskip -= 1;
+	}
+}
+
+/*
+ * Callback for sampling (Copied from ivfbuild.c#SampleCallback())
+ */
+static void
+SampleCallback(Relation index, ItemPointer tid, Datum *values,
+			   bool *isnull, bool tupleIsAlive, void *state)
+{
+	HnswBuildState *buildstate = (HnswBuildState *) state;
+	MemoryContext oldCtx;
+
+	/* Skip nulls */
+	if (isnull[0])
+		return;
+
+	/* Use memory context since detoast can allocate */
+	oldCtx = MemoryContextSwitchTo(buildstate->tmpCtx);
+
+	/* Add sample */
+	AddSample(values, buildstate);
+
+	/* Reset memory context */
+	MemoryContextSwitchTo(oldCtx);
+	MemoryContextReset(buildstate->tmpCtx);
+}
+
+/*
+ * Sample rows with same logic as ANALYZE (Copied from ivfbuild.c#SampleRows())
+ */
+static void
+SampleRows(HnswBuildState * buildstate)
+{
+	VectorArray samples = (VectorArray) buildstate->samples;
+	int			targsamples = samples->maxlen;
+	BlockNumber totalblocks = RelationGetNumberOfBlocks(buildstate->heap);
+
+	buildstate->rowstoskip = -1;
+
+	BlockSampler_Init(&buildstate->bs, totalblocks, targsamples, RandomInt());
+
+	reservoir_init_selection_state(&buildstate->rstate, targsamples);
+	while (BlockSampler_HasMore(&buildstate->bs))
+	{
+		BlockNumber targblock = BlockSampler_Next(&buildstate->bs);
+
+		table_index_build_range_scan(buildstate->heap, buildstate->index, buildstate->indexInfo,
+									 false, true, false, targblock, 1, SampleCallback, (void *) buildstate, NULL);
+	}
+}
+
+static void
+KmeansImpl(Relation index, VectorArray samples, VectorArray centers, HnswBuildState * buildstate)
+{
+	const IvfflatTypeInfo typeInfo = {
+		.maxDimensions = buildstate->typeInfo->maxDimensions,
+		.normalize = buildstate->typeInfo->normalize,
+		.itemSize = buildstate->typeInfo->itemSize,
+		.updateCenter = buildstate->typeInfo->updateCenter,
+		.sumCenter = buildstate->typeInfo->sumCenter
+	};
+	const KmeansInfo kmeansInfo = {
+		.procinfo = buildstate->support.procinfo,
+		.normprocinfo = NULL,	/* No normalization for PQ */
+		.collation = buildstate->support.collation
+	};
+
+	/* TODO Move k-means implementation to a file that can be referenced by both HNSW and IVFFlat */
+	IvfflatKmeans(index, samples, centers, &typeInfo, &kmeansInfo);
+}
+
+/*
+ * Train PQ centroids for each subvector
+ */
+static void
+TrainPQCentroids(Relation index, VectorArray samples, HnswNeighborMetadataState * metastate, HnswBuildState * buildstate)
+{
+	VectorArray subvectorSamples;
+
+	/* Allocate centroids array */
+	metastate->centroids = (VectorArray *) palloc0(sizeof(VectorArray) * metastate->m);
+
+	/* Allocate samples for subvectors */
+	subvectorSamples = VectorArrayInit(samples->length, metastate->subvectorDim, buildstate->typeInfo->itemSize(metastate->subvectorDim));
+	subvectorSamples->length = samples->length;
+
+	for (int i = 0; i < metastate->m; i++)
+	{
+		int			startDim = i * metastate->subvectorDim;
+		int			endDim = Min(startDim + metastate->subvectorDim, buildstate->dimensions);
+		int			subvectorDim = endDim - startDim;
+		int			itemSize = buildstate->typeInfo->itemSize(subvectorDim);
+
+		/* Extract sub-vectors */
+		for (int j = 0; j < samples->length; j++)
+		{
+			Vector	   *srcVec = (Vector *) VectorArrayGet(samples, j);
+			Vector	   *dstVec = (Vector *) VectorArrayGet(subvectorSamples, j);
+			float	   *srcData = srcVec->x + startDim;
+			float	   *dstData = dstVec->x;
+
+			/* Set vector header */
+			SET_VARSIZE(dstVec, itemSize);
+			dstVec->dim = subvectorDim;
+
+			/* Copy actual data */
+			for (int d = 0; d < subvectorDim; d++)
+				dstData[d] = srcData[d];
+
+			/* Initialize padding elements with 0.0f (if any) */
+			for (int d = subvectorDim; d < metastate->subvectorDim; d++)
+				dstData[d] = 0.0f;
+		}
+
+		/* Compute centroids for sub-vectors */
+		metastate->centroids[i] = VectorArrayInit(HNSW_PQ_NUM_CENTROIDS, subvectorDim, itemSize);
+		KmeansImpl(index, subvectorSamples, metastate->centroids[i], buildstate);
+	}
+
+	/* Free subsamples */
+	VectorArrayFree(subvectorSamples);
+}
+
+/* This function is implemented based on ivfbuild.c#ComputeCenters() */
+static void
+InitPQCentroids(Relation index, HnswBuildState * buildstate)
+{
+	HnswNeighborMetadataState    *metastate = (HnswNeighborMetadataState *) buildstate->neighborMetadataState;
+	VectorArray 	   *samples = (VectorArray *) &buildstate->samples;
+	int					numSamples;
+
+	metastate->subvectorDim = CalculateOptimalPQSubvectorDim(buildstate->dimensions);
+	metastate->m = buildstate->dimensions / metastate->subvectorDim;
+
+	if (buildstate->dimensions % metastate->subvectorDim != 0)
+	{
+		/* Account for padding in last subvector */
+		metastate->m++;
+	}
+
+	/*
+	 * Target 50 samples per centroid and the number of samples has a large effect
+	 * on index build time
+	 */
+	numSamples = HNSW_PQ_NUM_CENTROIDS * 50;
+
+	/* Skip samples for unlogged table */
+	if (buildstate->heap == NULL)
+		numSamples = 1;
+
+	/* Sample rows */
+	/* TODO Ensure within maintenance_work_mem */
+	*samples = VectorArrayInit(numSamples, buildstate->dimensions, buildstate->typeInfo->itemSize(buildstate->dimensions));
+
+	if (buildstate->heap != NULL)
+	{
+		SampleRows(buildstate);
+
+		if ((*samples)->length < HNSW_PQ_NUM_CENTROIDS)
+		{
+			ereport(NOTICE,
+					(errmsg("hnsw index metadata created with little data"),
+					 errdetail("This will cause low recall."),
+					 errhint("Drop the index until the table has more data.")));
+		}
+	}
+
+	/* Train PQ centroids for each subvector */
+	TrainPQCentroids(index, *samples, metastate, buildstate);
+
+	/* Free samples before we allocate more memory */
+	VectorArrayFree(*samples);
+}
+
+void
+HnswInitNeighborMetadataState(Relation index, HnswBuildState * buildstate)
+{
+	HnswNeighborMetadataState *metastate = (HnswNeighborMetadataState *) palloc(sizeof(HnswNeighborMetadataState));
+
+	/* Initialize with default values */
+	metastate->m = 0;
+	metastate->subvectorDim = 0;
+	metastate->centroids = NULL;
+
+	buildstate->neighborMetadataState = (void *) metastate;
+
+	InitPQCentroids(index, buildstate);
+}
+
+void
+HnswFreeNeighborMetadataState(HnswNeighborMetadataState * metastate)
+{
+	for (int i = 0; i < metastate->m; i++)
+		VectorArrayFree(metastate->centroids[i]);
+
+	if (metastate)
+		pfree(metastate);
+}
+
+/*
+ * Calculate the distance between values (Copied from hnswutils.c#HnswGetDistance())
+ */
+static inline double
+HnswGetDistance(Datum a, Datum b, HnswSupport * support)
+{
+	return DatumGetFloat8(FunctionCall2Coll(support->procinfo, support->collation, a, b));
+}
+
+static void
+PQEncodeVector(uint8 *dst, Datum v, HnswNeighborMetadataState * metastate, HnswSupport * support) {
+	Vector	   *vec = DatumGetVector(v);
+	Vector	   *sv;
+
+	/* Initialize entire dst array with zeros */
+	memset(dst, 0, HNSW_NEIGHBOR_VECTOR_L2_METADATA_BYTES);
+
+	/* Create temporary subvector for reuse (allocate for maximum subvector dimension) */
+	sv = InitVector(metastate->subvectorDim);
+
+	/* Encode each subvector */
+	for (int i = 0; i < metastate->m; i++)
+	{
+		int			startDim = i * metastate->subvectorDim;
+		int			endDim = Min(startDim + metastate->subvectorDim, vec->dim);
+		int			subvectorDim = endDim - startDim;
+		VectorArray	centroids = metastate->centroids[i];
+		int			bestCentroid = -1;
+		float		bestDistance = FLT_MAX;
+
+		/* Update subvector dimension and copy data */
+		sv->dim = subvectorDim;
+
+		for (int d = 0; d < subvectorDim; d++)
+			sv->x[d] = vec->x[startDim + d];
+
+		/* Initialize padding elements with 0.0f (if any) */
+		for (int d = subvectorDim; d < metastate->subvectorDim; d++)
+			sv->x[d] = 0.0f;
+
+		/* Find nearest centroid */
+		for (int c = 0; c < HNSW_PQ_NUM_CENTROIDS; c++)
+		{
+			Vector	   *centroidVec = (Vector *) VectorArrayGet(centroids, c);
+			double		distance = HnswGetDistance(PointerGetDatum(sv), PointerGetDatum(centroidVec), support);
+
+			if (distance < bestDistance)
+			{
+				bestDistance = (float) distance;
+				bestCentroid = c;
+			}
+		}
+
+		Assert(bestCentroid >= 0 && bestCentroid < HNSW_PQ_NUM_CENTROIDS);
+
+		/* Store the index of the best centroid */
+		dst[i] = (uint8) bestCentroid;
+	}
+
+	pfree(sv);
+}
+
+void
+HnswSetVectorL2NeighborMetadata(char *dst, Datum v, void * metastate, HnswSupport * support) {
+	Assert(DatumGetPointer(v) != NULL);
+	PQEncodeVector((uint8 *) dst, v, metastate, support);
+}
+
+static void
+PQDecodeVector(Datum dst, uint8 *encoded, HnswNeighborMetadataState * metastate)
+{
+	Vector	   *dv = DatumGetVector(dst);
+
+	for (int i = 0; i < metastate->m; i++)
+	{
+		int			startDim = i * metastate->subvectorDim;
+		int			endDim = Min(startDim + metastate->subvectorDim, dv->dim);
+		int			subvectorDim = endDim - startDim;
+		uint8		centroidIdx = encoded[i];
+		VectorArray	centroids = metastate->centroids[i];
+
+		Assert(centroidIdx >= 0 && centroidIdx < HNSW_PQ_NUM_CENTROIDS);
+
+		/* Get the centroid vector */
+		Vector	   *centroidVec = (Vector *) VectorArrayGet(centroids, centroidIdx);
+		float	   *centroidData = centroidVec->x;
+
+		/* Copy centroid data to output vector (only actual dimensions, skip padding) */
+		for (int d = 0; d < subvectorDim; d++)
+			dv->x[startDim + d] = centroidData[d];
+	}
+}
+
+void
+HnswEstimateVectorL2Distances(Datum q, HnswNeighborEntry entries, int *unvisitedIndexes, int count, void * metastate, HnswSupport * support) {
+	uint8	encoded[HNSW_NEIGHBOR_VECTOR_L2_METADATA_BYTES];
+	Vector *qv = DatumGetVector(q);
+	Vector *decoded;
+
+	Assert(qv != NULL);
+
+	decoded = InitVector(qv->dim);
+
+	for (int i = 0; i < count; i++)
+	{
+		HnswNeighborEntry entry = &entries[unvisitedIndexes[i]];
+
+		if (!ItemPointerIsValid(&entry->indextid))
+			break;
+
+		memcpy(&encoded[0], entry->metadata, HNSW_NEIGHBOR_VECTOR_L2_METADATA_BYTES);
+		PQDecodeVector(PointerGetDatum(decoded), &encoded[0], metastate);
+
+		entry->distance = HnswGetDistance(PointerGetDatum(decoded), q, support);
+	}
+
+	pfree(decoded);
+}
+
+/*
+ * Estimate size of PQ metadata for shared memory
+ */
+Size
+HnswEstimateSharedNeighborMetadataState(HnswNeighborMetadataState * metastate)
+{
+	Size size = 0;
+
+	if (metastate != NULL)
+	{
+		/* Add header size */
+		size = add_size(size, BUFFERALIGN(sizeof(HnswSharedNeighborMetadataState)));
+
+		/* Add centroids data size */
+		for (int m = 0; m < metastate->m; m++)
+		{
+			VectorArray subvectorCentroids = metastate->centroids[m];
+			size = add_size(size, subvectorCentroids->itemsize * subvectorCentroids->maxlen);
+		}
+	}
+
+	return size;
+}
+
+/*
+ * Copy metadata state to shared memory
+ */
+char *
+HnswCopyNeighborMetadataStateToShm(ParallelContext * pcxt, HnswNeighborMetadataState * metastate, Size estmeta)
+{
+	HnswSharedNeighborMetadataState    *sharedstate;
+	Size	totalSize = 0;
+	char   *shared;
+	char   *centroidsArea;
+
+	shared = shm_toc_allocate(pcxt->toc, estmeta);
+
+	/* Build shared PQ state header */
+	sharedstate = (HnswSharedNeighborMetadataState *) shared;
+	sharedstate->m = metastate->m;
+	sharedstate->subvectorDim = metastate->subvectorDim;
+	sharedstate->centroidsOffset = BUFFERALIGN(sizeof(HnswSharedNeighborMetadataState));
+
+	/* Copy centroids data after header */
+	centroidsArea = shared + sharedstate->centroidsOffset;
+
+	for (int m = 0; m < metastate->m; m++)
+	{
+		VectorArray subvectorCentroids = metastate->centroids[m];
+		Size 		subvectorSize = subvectorCentroids->itemsize * subvectorCentroids->maxlen;
+
+		memcpy(centroidsArea + totalSize, subvectorCentroids->items, subvectorSize);
+		totalSize += subvectorSize;
+	}
+
+	sharedstate->centroidsSize = totalSize;
+
+	return shared;
+}
+
+HnswNeighborMetadataState *
+HnswLoadNeighborMetadataStateFromShm(char *shared, const HnswTypeInfo * typeInfo)
+{
+	HnswSharedNeighborMetadataState	   *sharedstate = (HnswSharedNeighborMetadataState *) shared;
+	HnswNeighborMetadataState		   *metastate = palloc(sizeof(HnswNeighborMetadataState));
+	char   *centroidsArea;
+	Size	offset = 0;
+
+	/* Allocate local PQ state */
+	metastate = palloc(sizeof(HnswNeighborMetadataState));
+	metastate->m = sharedstate->m;
+	metastate->subvectorDim = sharedstate->subvectorDim;
+	metastate->centroids = palloc(sizeof(VectorArray) * metastate->m);
+
+	/* Restore centroids from shared memory */
+	centroidsArea = shared + sharedstate->centroidsOffset;
+
+	for (int m = 0; m < metastate->m; m++)
+	{
+		VectorArray	subvectorCentroids;
+		Size 		subvectorSize;
+
+		metastate->centroids[m] = VectorArrayInit(HNSW_PQ_NUM_CENTROIDS, metastate->subvectorDim, typeInfo->itemSize(metastate->subvectorDim));
+		subvectorCentroids = metastate->centroids[m];
+		subvectorSize = subvectorCentroids->itemsize * subvectorCentroids->maxlen;
+
+		memcpy(subvectorCentroids->items, centroidsArea + offset, subvectorSize);
+		subvectorCentroids->length = subvectorCentroids->maxlen;
+		offset += subvectorSize;
+	}
+
+	return (void *) metastate;
+}
+
+/*
+ * Create centroid pages for neighbor metadata
+ */
+BlockNumber
+HnswCreateCodebookPages(HnswBuildState * buildstate, HnswNeighborMetadataState * metastate, uint16 *pageCount)
+{
+	Relation	index = buildstate->index;
+	ForkNumber	forkNum = buildstate->forkNum;
+	Buffer		buf;
+	Page		page;
+	BlockNumber startBlkno;
+	uint16		pagesUsed = 0;
+	HnswCentroidTuple	ctup;
+
+	/* Allocate memory for centroid tuple */
+	ctup = palloc0(HNSW_TUPLE_ALLOC_SIZE);
+
+	/* Create first page */
+	buf = HnswNewBuffer(index, forkNum);
+	page = BufferGetPage(buf);
+	HnswInitPage(buf, page);
+	startBlkno = BufferGetBlockNumber(buf);
+	pagesUsed = 1;
+
+	/* Write centroids for each subvector */
+	for (int m = 0; m < metastate->m; m++)
+	{
+		VectorArray subvectorCentroids = metastate->centroids[m];
+
+		for (int c = 0; c < HNSW_PQ_NUM_CENTROIDS; c++)
+		{
+			Vector *centroid = (Vector *) VectorArrayGet(subvectorCentroids, c);
+			Size	ctupSize = HNSW_CENTROID_TUPLE_SIZE(centroid->dim);
+
+			/* Create new page if current page doesn't have enough space */
+			if (PageGetFreeSpace(page) < ctupSize)
+			{
+				/* Commit current page */
+				MarkBufferDirty(buf);
+				UnlockReleaseBuffer(buf);
+
+				/* Create new page */
+				buf = HnswNewBuffer(index, forkNum);
+				page = BufferGetPage(buf);
+				HnswInitPage(buf, page);
+				pagesUsed++;
+			}
+
+			/* Set centroid tuple */
+			MemSet(ctup, 0, HNSW_TUPLE_ALLOC_SIZE);
+			ctup->type = HNSW_CENTROID_TUPLE_TYPE;
+			ctup->subvectorIndex = m;
+			ctup->centroidIndex = c;
+			ctup->dimensions = centroid->dim;
+			memcpy(&ctup->data, centroid, VECTOR_SIZE(centroid->dim));
+
+			/* Add to page */
+			if (PageAddItem(page, (Item) ctup, ctupSize, InvalidOffsetNumber, false, false) == InvalidOffsetNumber)
+				elog(ERROR, "failed to add centroid item to \"%s\"", RelationGetRelationName(index));
+		}
+	}
+
+	/* Commit last page */
+	MarkBufferDirty(buf);
+	UnlockReleaseBuffer(buf);
+
+	pfree(ctup);
+
+	*pageCount = pagesUsed;
+
+	return startBlkno;
+}
+
+/*
+ * Load neighbor metadata state from index metapage and centroid pages
+ */
+HnswNeighborMetadataState *
+HnswLoadNeighborMetadataStateFromDisk(Relation index)
+{
+	Buffer				buf;
+	Page				page;
+	HnswMetaPage 		metap;
+	HnswNeighborMetadataState	*metastate = NULL;
+	const HnswTypeInfo *typeInfo = HnswGetTypeInfo(index);
+
+	/* Read metapage */
+	buf = ReadBuffer(index, HNSW_METAPAGE_BLKNO);
+	LockBuffer(buf, BUFFER_LOCK_SHARE);
+	page = BufferGetPage(buf);
+	metap = HnswPageGetMeta(page);
+
+	if (metap->hasNeighborMetadata)
+	{
+		/* Initialize PQState */
+		metastate = palloc0(sizeof(HnswNeighborMetadataState));
+		metastate->subvectorDim = metap->pqSubvectorDim;
+		metastate->m = metap->pqM;
+		metastate->centroids = palloc0(sizeof(VectorArray) * metastate->m);
+
+		/* Initialize centroid arrays for each subvector */
+		for (int m = 0; m < metastate->m; m++)
+		{
+			Size	itemsize = typeInfo->itemSize(metastate->subvectorDim);
+			metastate->centroids[m] = VectorArrayInit(HNSW_PQ_NUM_CENTROIDS, metastate->subvectorDim, itemsize);
+		}
+
+		UnlockReleaseBuffer(buf);
+
+		/* Load centroid data from pages */
+		LoadCentroidsFromPages(index, metap->neighborMetadataStartBlkno, metap->neighborMetadataPageCount, metastate);
+	}
+	else
+		UnlockReleaseBuffer(buf);
+
+	return metastate;
+}
\ No newline at end of file
diff --git a/src/hnswmeta.h b/src/hnswmeta.h
new file mode 100644
index 0000000..e14f3e6
--- /dev/null
+++ b/src/hnswmeta.h
@@ -0,0 +1,53 @@
+#ifndef HNSW_SIMHASH_H
+#define HNSW_SIMHASH_H
+
+/* TODO This header file can be merged with hnsw.h */
+#include "postgres.h"
+
+#include "access/parallel.h"
+#include "hnsw.h"
+#include "ivfflat.h"			/* For reusing some structs and functions */
+#include "utils/relcache.h"
+
+/* Neighbor metadata */
+#define HNSW_NEIGHBOR_VECTOR_L2_METADATA_BYTES		16	/* 16B PQ encoded distance */
+
+/* Product Quantization */
+#define HNSW_PQ_NUM_CENTROIDS	256
+
+/* Utility macros */
+#define HnswVectorIsLoaded(base, element) (DatumGetPointer(HnswGetValue((base), (element))) != NULL)
+
+/* As post-processing of HNSW search, recheck data points whose distance to query q has been estimated */
+#define HNSW_SCAN_ESTIMATED_DISTANCE_QUEUE
+
+typedef struct HnswNeighborMetadataState {
+	int				subvectorDim;	/* Dimension of each sub-vector */
+	int				m;				/* Number of sub-vectors */
+	VectorArray    *centroids;		/* Centroids for each sub-vector, the number of centroids per sub-vector is HNSW_PQ_NUM_CENTROIDS */
+} HnswNeighborMetadataState;
+
+typedef struct HnswSharedNeighborMetadataState
+{
+	int			subvectorDim;		/* Dimension of each sub-vector */
+	int			m;					/* Number of subvectors */
+	Size		centroidsOffset;	/* Offset to centroids data in shared memory */
+	Size		centroidsSize;		/* Total size of centroids data */
+}			HnswSharedNeighborMetadataState;
+
+/* Methods */
+bool	HnswIsVectorL2Distance(FmgrInfo * distanceProcinfo);
+void	HnswSetVectorL2NeighborMetadata(char *dst, Datum v, void * metastate, HnswSupport * support);
+void	HnswEstimateVectorL2Distances(Datum q, HnswNeighborEntry entries, int *unvisitedIndexes, int count, void * metastate, HnswSupport * support);
+Size	HnswVectorItemSize(int dimensions);
+void	HnswVectorUpdateCenter(Pointer v, int dimensions, float *x);
+void	HnswVectorSumCenter(Pointer v, float *x);
+void	HnswInitNeighborMetadataState(Relation index, HnswBuildState * buildstate);
+void	HnswFreeNeighborMetadataState(HnswNeighborMetadataState * metastate);
+Size	HnswEstimateSharedNeighborMetadataState(HnswNeighborMetadataState * metastate);
+char   *HnswCopyNeighborMetadataStateToShm(ParallelContext * pcxt, HnswNeighborMetadataState * metastate, Size estmeta);
+HnswNeighborMetadataState *HnswLoadNeighborMetadataStateFromShm(char *shared, const HnswTypeInfo * typeInfo);
+BlockNumber HnswCreateCodebookPages(HnswBuildState * buildstate, HnswNeighborMetadataState * metastate, uint16 *pageCount);
+HnswNeighborMetadataState *HnswLoadNeighborMetadataStateFromDisk(Relation index);
+
+#endif
diff --git a/src/hnswpq.c b/src/hnswpq.c
new file mode 100644
index 0000000..71b2f35
--- /dev/null
+++ b/src/hnswpq.c
@@ -0,0 +1 @@
+#include "postgres.h"
diff --git a/src/hnswscan.c b/src/hnswscan.c
index 955998a..7bcffbd 100644
--- a/src/hnswscan.c
+++ b/src/hnswscan.c
@@ -2,6 +2,7 @@
 
 #include "access/relscan.h"
 #include "hnsw.h"
+#include "hnswmeta.h"
 #include "pgstat.h"
 #include "storage/bufmgr.h"
 #include "storage/lmgr.h"
@@ -16,6 +17,7 @@ GetScanItems(IndexScanDesc scan, Datum value)
 {
 	HnswScanOpaque so = (HnswScanOpaque) scan->opaque;
 	Relation	index = scan->indexRelation;
+	const		HnswTypeInfo *typeInfo = so->typeInfo;
 	HnswSupport *support = &so->support;
 	List	   *ep;
 	List	   *w;
@@ -37,11 +39,11 @@ GetScanItems(IndexScanDesc scan, Datum value)
 
 	for (int lc = entryPoint->level; lc >= 1; lc--)
 	{
-		w = HnswSearchLayer(base, q, ep, 1, lc, index, support, m, false, NULL, NULL, NULL, true, NULL);
+		w = HnswSearchLayer(base, q, ep, 1, lc, index, typeInfo, support, m, false, NULL, NULL, NULL, true, NULL, true, so->neighborMetadataState);
 		ep = w;
 	}
 
-	return HnswSearchLayer(base, q, ep, hnsw_ef_search, 0, index, support, m, false, NULL, &so->v, hnsw_iterative_scan != HNSW_ITERATIVE_SCAN_OFF ? &so->discarded : NULL, true, &so->tuples);
+	return HnswSearchLayer(base, q, ep, hnsw_ef_search, 0, index, typeInfo, support, m, false, NULL, &so->v, hnsw_iterative_scan != HNSW_ITERATIVE_SCAN_OFF ? &so->discarded : NULL, true, &so->tuples, true, so->neighborMetadataState);
 }
 
 /*
@@ -72,7 +74,7 @@ ResumeScanItems(IndexScanDesc scan)
 		ep = lappend(ep, sc);
 	}
 
-	return HnswSearchLayer(base, &so->q, ep, batch_size, 0, index, &so->support, so->m, false, NULL, &so->v, &so->discarded, false, &so->tuples);
+	return HnswSearchLayer(base, &so->q, ep, batch_size, 0, index, so->typeInfo, &so->support, so->m, false, NULL, &so->v, &so->discarded, false, &so->tuples, true, so->neighborMetadataState);
 }
 
 /*
@@ -131,6 +133,9 @@ hnswbeginscan(Relation index, int nkeys, int norderbys)
 	/* Set support functions */
 	HnswInitSupport(&so->support, index);
 
+	/* Load neighbor metadata state */
+	so->neighborMetadataState = HnswLoadNeighborMetadataStateFromDisk(index);
+
 	/*
 	 * Use a lower max allocation size than default to allow scanning more
 	 * tuples for iterative search before exceeding work_mem
diff --git a/src/hnswutils.c b/src/hnswutils.c
index 7afed25..fc269f3 100644
--- a/src/hnswutils.c
+++ b/src/hnswutils.c
@@ -1,5 +1,6 @@
 #include "postgres.h"
 
+#include <float.h>
 #include <math.h>
 
 #include "access/generic_xlog.h"
@@ -8,6 +9,7 @@
 #include "common/hashfn.h"
 #include "fmgr.h"
 #include "hnsw.h"
+#include "hnswmeta.h"
 #include "lib/pairingheap.h"
 #include "sparsevec.h"
 #include "storage/bufmgr.h"
@@ -334,6 +336,29 @@ HnswGetEntryPoint(Relation index)
 	return entryPoint;
 }
 
+/*
+ * Get head block number from meta page
+ */
+BlockNumber
+HnswGetHeadBlockNumber(Relation index)
+{
+	Buffer		buf;
+	Page		page;
+	HnswMetaPage metap;
+	BlockNumber headBlkno;
+
+	buf = ReadBuffer(index, HNSW_METAPAGE_BLKNO);
+	LockBuffer(buf, BUFFER_LOCK_SHARE);
+	page = BufferGetPage(buf);
+	metap = HnswPageGetMeta(page);
+
+	headBlkno = metap->headBlkno;
+
+	UnlockReleaseBuffer(buf);
+
+	return headBlkno;
+}
+
 /*
  * Update the metapage info
  */
@@ -447,7 +472,7 @@ HnswSetElementTuple(char *base, HnswElementTuple etup, HnswElement element)
  * Set neighbor tuple
  */
 void
-HnswSetNeighborTuple(char *base, HnswNeighborTuple ntup, HnswElement e, int m)
+HnswSetNeighborTuple(char *base, HnswNeighborTuple ntup, HnswElement e, int m, const HnswTypeInfo * typeInfo, HnswSupport * support, void * metastate, bool neighborMetadata)
 {
 	int			idx = 0;
 
@@ -460,7 +485,8 @@ HnswSetNeighborTuple(char *base, HnswNeighborTuple ntup, HnswElement e, int m)
 
 		for (int i = 0; i < lm; i++)
 		{
-			ItemPointer indextid = &ntup->indextids[idx++];
+			int			cidx = idx++;
+			ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, cidx, typeInfo, neighborMetadata);
 
 			if (i < neighbors->length)
 			{
@@ -468,6 +494,12 @@ HnswSetNeighborTuple(char *base, HnswNeighborTuple ntup, HnswElement e, int m)
 				HnswElement hce = HnswPtrAccess(base, hc->element);
 
 				ItemPointerSet(indextid, hce->blkno, hce->offno);
+
+				if (neighborMetadata && typeInfo->neighborMetadataBytes > 0)
+				{
+					char *metadata = HnswNeighborEntryMetadataAccess(ntup->entries, cidx, typeInfo, neighborMetadata);
+					typeInfo->setNeighborMetadata(metadata, HnswGetValue(base, hce), metastate, support);
+				}
 			}
 			else
 				ItemPointerSetInvalid(indextid);
@@ -570,6 +602,43 @@ HnswLoadElement(HnswElement element, double *distance, HnswQuery * q, Relation i
 	HnswLoadElementImpl(element->blkno, element->offno, distance, q, index, support, loadVec, maxDistance, &element);
 }
 
+static void
+LoadElementInSearchCandidate(char *base, HnswSearchCandidate *c, HnswQuery * q, Relation index, HnswSupport * support, bool loadVec)
+{
+	HnswElement element = NULL;
+	BlockNumber blkno = ItemPointerGetBlockNumber(&c->indextid);
+	OffsetNumber offno = ItemPointerGetOffsetNumber(&c->indextid);
+	Assert(HnswPtrIsNull(base, c->element));
+	HnswLoadElementImpl(blkno, offno, &c->distance, q, index, support, loadVec, NULL, &element);
+	HnswPtrStore(base, c->element, element);
+}
+
+static void
+LoadVectorInElement(Relation index, HnswElement element)
+{
+	Buffer  buf;
+	Page    page;
+	HnswElementTuple etup;
+	char   *base = NULL;
+	Datum   vec;
+
+	Assert(element->value == NULL);
+
+	/* Read vector */
+	buf = ReadBuffer(index, element->blkno);
+	LockBuffer(buf, BUFFER_LOCK_SHARE);
+	page = BufferGetPage(buf);
+
+	etup = (HnswElementTuple) PageGetItem(page, PageGetItemId(page, element->offno));
+
+	Assert(HnswIsElementTuple(etup));
+
+	vec = datumCopy(PointerGetDatum(&etup->data), false, -1);
+	UnlockReleaseBuffer(buf);
+
+	HnswPtrStore(base, element->value, DatumGetPointer(vec));
+}
+
 /*
  * Get the distance for an element
  */
@@ -594,6 +663,17 @@ HnswInitSearchCandidate(char *base, HnswElement element, double distance)
 	return sc;
 }
 
+static HnswSearchCandidate *
+InitSearchCandidateWithEmptyElement(HnswNeighborEntry ne)
+{
+	HnswSearchCandidate *sc = palloc(sizeof(HnswSearchCandidate));
+
+	memset(&sc->element, 0, sizeof(HnswElementPtr));
+	sc->indextid = ne->indextid;
+	sc->distance = ne->distance;
+	return sc;
+}
+
 /*
  * Create a candidate for the entry point
  */
@@ -748,11 +828,13 @@ HnswLoadUnvisitedFromMemory(char *base, HnswElement element, HnswUnvisited * unv
  * Load neighbor index TIDs
  */
 bool
-HnswLoadNeighborTids(HnswElement element, ItemPointerData *indextids, Relation index, int m, int lm, int lc)
+HnswLoadNeighborEntries(HnswElement element, HnswNeighborEntryData *entries, Relation index, const HnswTypeInfo * typeInfo, int m, int lm, int lc, bool neighborMetadata)
 {
 	Buffer		buf;
 	Page		page;
 	HnswNeighborTuple ntup;
+	char		eBuf[HNSW_MAX_M * 2 * HNSW_NEIGHBOR_TUPLE_ENTRY_MAX_SIZE];
+	int			entrySize = HNSW_NEIGHBOR_TUPLE_ENTRY_SIZE(typeInfo, neighborMetadata);
 	int			start;
 
 	buf = ReadBuffer(index, element->neighborPage);
@@ -773,37 +855,158 @@ HnswLoadNeighborTids(HnswElement element, ItemPointerData *indextids, Relation i
 
 	/* Copy to minimize lock time */
 	start = (element->level - lc) * m;
-	memcpy(indextids, ntup->indextids + start, lm * sizeof(ItemPointerData));
+	memcpy(eBuf, ntup->entries + (start * entrySize), lm * entrySize);
 
 	UnlockReleaseBuffer(buf);
+
+	for (int i = 0; i < lm; i++)
+	{
+		HnswNeighborEntry ne = &entries[i];
+		int offset = i * entrySize;
+
+		memcpy(&ne->indextid, eBuf + offset, sizeof(ItemPointerData));
+
+		if (!ItemPointerIsValid(&ne->indextid))
+			break;
+
+		if (typeInfo->neighborMetadataBytes > 0)
+			memcpy(&ne->metadata, eBuf + offset + sizeof(ItemPointerData), typeInfo->neighborMetadataBytes);
+	}
+
 	return true;
 }
 
+static int
+CompareNearestNeighborEntries(const void *a, const void *b)
+{
+	HnswNeighborEntryData *entryA = (HnswNeighborEntryData *) a;
+	HnswNeighborEntryData *entryB = (HnswNeighborEntryData *) b;
+
+	if (entryA->distance < entryB->distance)
+		return -1;
+	else if (entryA->distance > entryB->distance)
+		return 1;
+	else
+		return 0;
+}
+
+static void
+EstimateAndSortDistancesFromMetadata(char *base, HnswElement element, HnswQuery * q, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, void * metastate, HnswNeighborEntryData *entries, int *unvisitedIndexes, int *unvisitedLength)
+{
+	int maxNeighborEntries;
+
+	if (*unvisitedLength == 0)
+		return;
+
+	maxNeighborEntries = unvisitedIndexes[(*unvisitedLength) - 1] + 1;
+
+	/*
+	 * Initialize with DBL_MAX so that unused entries are placed
+	 * at the end of the array after sorting
+	 */
+	for (int i = 0; i < maxNeighborEntries; i++)
+		entries[i].distance = DBL_MAX;
+
+	/* Estimate distances from neighbor metadata */
+	typeInfo->estimateDistances(q->value, entries, unvisitedIndexes, *unvisitedLength, metastate, support);
+
+	/* Sort distances in ascending order for processing prioritization */
+	qsort(entries, maxNeighborEntries, sizeof(HnswNeighborEntryData), CompareNearestNeighborEntries);
+}
+
 /*
  * Load unvisited neighbors from disk
+ * If useMetadata is true, compute estimated distances from the neighbor metadata to avoid unencessary block reads
  */
 static void
-HnswLoadUnvisitedFromDisk(HnswElement element, HnswUnvisited * unvisited, int *unvisitedLength, visited_hash * v, Relation index, int m, int lm, int lc)
+HnswLoadUnvisitedFromDisk(char *base, HnswElement element, HnswQuery * q, HnswUnvisited * unvisited, int *unvisitedLength, visited_hash * v, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, int m, int lm, int lc, bool neighborMetadata, bool useMetadata, int topk, pairingheap * E, void * metastate)
 {
-	ItemPointerData indextids[HNSW_MAX_M * 2];
+	HnswNeighborEntryData entries[HNSW_MAX_M * 2];
+	int unvisitedIndexes[HNSW_MAX_M * 2];
 
 	*unvisitedLength = 0;
 
-	if (!HnswLoadNeighborTids(element, indextids, index, m, lm, lc))
+	if (!HnswLoadNeighborEntries(element, entries, index, typeInfo, m, lm, lc, neighborMetadata))
 		return;
 
 	for (int i = 0; i < lm; i++)
 	{
-		ItemPointer indextid = &indextids[i];
+		ItemPointer indextid = &entries[i].indextid;
 		bool		found;
 
 		if (!ItemPointerIsValid(indextid))
 			break;
 
-		tidhash_insert(v->tids, *indextid, &found);
+		if (useMetadata)
+		{
+			if (tidhash_lookup(v->tids, *indextid) == NULL)
+				unvisitedIndexes[(*unvisitedLength)++] = i;
+		}
+		else
+		{
+			tidhash_insert(v->tids, *indextid, &found);
+
+			if (!found)
+				unvisited[(*unvisitedLength)++].entry = entries[i];
+		}
+	}
 
-		if (!found)
-			unvisited[(*unvisitedLength)++].indextid = *indextid;
+	/* Compute estimated distances from the neighbor metadata */
+	if (useMetadata)
+	{
+		EstimateAndSortDistancesFromMetadata(base, element, q, index, typeInfo, support, metastate, entries, unvisitedIndexes, unvisitedLength);
+
+		for (int i = 0; i < *unvisitedLength; i++)
+		{
+			if (i < topk)
+			{
+				ItemPointer indextid = &entries[i].indextid;
+				bool		found;
+
+				tidhash_insert(v->tids, *indextid, &found);
+
+				Assert(!found);
+
+				unvisited[i].entry = entries[i];
+			}
+			else
+			{
+				/*
+				 * Add to the estimated distance queue E for rechecking entries in the end of search
+				 * Due to the variance in estimated distances caused by SimHash, an element's estimated distance
+				 * varies depending on which neighbor node it's estimated from, so we don't exclude
+				 * by tid and insert into the heap
+				 */
+				HnswSearchCandidate *sc = InitSearchCandidateWithEmptyElement(&entries[i]);
+				pairingheap_add(E, &sc->c_node);
+			}
+		}
+
+		/* Return only the topk nearest neighbor elements that are search candidates */
+		*unvisitedLength = *unvisitedLength < topk ? *unvisitedLength : topk;
+	}
+}
+
+static void
+RemoveFurthestCandidate(char *base, HnswElement eElement, int *wlen, int ef, HnswElement skipElement, pairingheap * W, pairingheap **discarded)
+{
+	/*
+	 * Do not count elements being deleted towards ef when vacuuming.
+	 * It would be ideal to do this for inserts as well, but this
+	 * could affect insert performance.
+	 */
+	if (CountElement(skipElement, eElement))
+	{
+		(*wlen)++;
+
+		/* No need to decrement wlen */
+		if (*wlen > ef)
+		{
+			HnswSearchCandidate *d = HnswGetSearchCandidate(w_node, pairingheap_remove_first(W));
+
+			if (discarded != NULL)
+				pairingheap_add(*discarded, &d->w_node);
+		}
 	}
 }
 
@@ -811,11 +1014,12 @@ HnswLoadUnvisitedFromDisk(HnswElement element, HnswUnvisited * unvisited, int *u
  * Algorithm 2 from paper
  */
 List *
-HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation index, HnswSupport * support, int m, bool inserting, HnswElement skipElement, visited_hash * v, pairingheap **discarded, bool initVisited, int64 *tuples)
+HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, int m, bool inserting, HnswElement skipElement, visited_hash * v, pairingheap **discarded, bool initVisited, int64 *tuples, bool candidatePruning, void * metastate)
 {
 	List	   *w = NIL;
 	pairingheap *C = pairingheap_allocate(CompareNearestCandidates, NULL);
 	pairingheap *W = pairingheap_allocate(CompareFurthestCandidates, NULL);
+	pairingheap *E = NULL;
 	int			wlen = 0;
 	visited_hash vh;
 	ListCell   *lc2;
@@ -825,6 +1029,10 @@ HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation in
 	HnswUnvisited *unvisited = palloc(lm * sizeof(HnswUnvisited));
 	int			unvisitedLength;
 	bool		inMemory = index == NULL;
+	bool		neighborMetadata = index != NULL ? HnswSupportNeighborMetadata(index) : false;
+	bool		useMetadata = hnsw_candidate_pruning && candidatePruning && neighborMetadata && DatumGetPointer(q->value) != NULL;
+	bool		monotonic = true;
+	double		prevDistance = DBL_MAX;
 
 	if (v == NULL)
 	{
@@ -847,6 +1055,9 @@ HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation in
 		localNeighborhood = palloc(neighborhoodSize);
 	}
 
+	if (useMetadata)
+		E = pairingheap_allocate(CompareNearestCandidates, NULL);
+
 	/* Add entry points to v, C, and W */
 	foreach(lc2, ep)
 	{
@@ -883,12 +1094,26 @@ HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation in
 		if (c->distance > f->distance)
 			break;
 
+		/*
+		 * When monotonically approaching query q, do best-first search based on estimated distances
+		 * instead of indiscriminately reading blocks.
+		 */
+		if (monotonic)
+		{
+			monotonic = c->distance <= prevDistance;
+			prevDistance = c->distance;
+		}
+
 		cElement = HnswPtrAccess(base, c->element);
 
+		/* Load vector to estimate distance from metadata */
+		if (useMetadata && !HnswVectorIsLoaded(base, cElement))
+			LoadVectorInElement(index, cElement);
+
 		if (inMemory)
 			HnswLoadUnvisitedFromMemory(base, cElement, unvisited, &unvisitedLength, v, lc, localNeighborhood, neighborhoodSize);
 		else
-			HnswLoadUnvisitedFromDisk(cElement, unvisited, &unvisitedLength, v, index, m, lm, lc);
+			HnswLoadUnvisitedFromDisk(base, cElement, q, unvisited, &unvisitedLength, v, index, typeInfo, support, m, lm, lc, neighborMetadata, useMetadata, monotonic && lc == 0 ? 1 : hnsw_distance_computation_topk, E, metastate);
 
 		/* OK to count elements instead of tuples */
 		if (tuples != NULL)
@@ -910,7 +1135,7 @@ HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation in
 			}
 			else
 			{
-				ItemPointer indextid = &unvisited[i].indextid;
+				ItemPointer indextid = &unvisited[i].entry.indextid;
 				BlockNumber blkno = ItemPointerGetBlockNumber(indextid);
 				OffsetNumber offno = ItemPointerGetOffsetNumber(indextid);
 
@@ -943,23 +1168,62 @@ HnswSearchLayer(char *base, HnswQuery * q, List *ep, int ef, int lc, Relation in
 			pairingheap_add(C, &e->c_node);
 			pairingheap_add(W, &e->w_node);
 
-			/*
-			 * Do not count elements being deleted towards ef when vacuuming.
-			 * It would be ideal to do this for inserts as well, but this
-			 * could affect insert performance.
-			 */
-			if (CountElement(skipElement, eElement))
-			{
-				wlen++;
+			RemoveFurthestCandidate(base, eElement, &wlen, ef, skipElement, W, discarded);
+		}
+	}
 
-				/* No need to decrement wlen */
-				if (wlen > ef)
-				{
-					HnswSearchCandidate *d = HnswGetSearchCandidate(w_node, pairingheap_remove_first(W));
+#if defined(HNSW_SCAN_ESTIMATED_DISTANCE_QUEUE)
+	/*
+	 * Finally, add the elements in E to W. Since E is sorted in order of distance proximity,
+	 * adding elements from E to W in the order they are retrieved will keep W sorted
+	 * by distance proximity as well.
+	 */
+	while (useMetadata && !pairingheap_is_empty(E))
+	{
+		HnswSearchCandidate *e = HnswGetSearchCandidate(c_node, pairingheap_remove_first(E));
+		HnswSearchCandidate *w = HnswGetSearchCandidate(w_node, pairingheap_first(W));
+		bool		found;
 
-					if (discarded != NULL)
-						pairingheap_add(*discarded, &d->w_node);
-				}
+		if (e->distance > w->distance)
+		{
+			/* Put back for iterative scans */
+			pairingheap_add(E, &e->c_node);
+			break;
+		}
+
+		tidhash_insert(v->tids, e->indextid, &found);
+
+		if (!found)
+		{
+			LoadElementInSearchCandidate(base, e, q, index, support, false);
+
+			pairingheap_add(W, &e->w_node);
+
+			RemoveFurthestCandidate(base, HnswPtrAccess(base, e->element), &wlen, ef, skipElement, W, discarded);
+		}
+	}
+#endif
+
+	/* Pruned elements are needed for iterative scans */
+	if (useMetadata && discarded != NULL)
+	{
+		while (!pairingheap_is_empty(E))
+		{
+			HnswSearchCandidate *e = HnswGetSearchCandidate(c_node, pairingheap_remove_first(E));
+			bool		found;
+
+			tidhash_insert(v->tids, e->indextid, &found);
+
+			if (!found)
+			{
+				/*
+				 * TODO Essentially, it seems unnecessary to load Element here, but it's unclear whether
+				 * there would be any issues if we assume that the estimated distances
+				 * have reasonably high accuracy
+				 */
+				LoadElementInSearchCandidate(base, e, q, index, support, false);
+
+				pairingheap_add(*discarded, &e->w_node);
 			}
 		}
 	}
@@ -1267,7 +1531,7 @@ PrecomputeHash(char *base, HnswElement element)
  * Algorithm 1 from paper
  */
 void
-HnswFindElementNeighbors(char *base, HnswElement element, HnswElement entryPoint, Relation index, HnswSupport * support, int m, int efConstruction, bool existing)
+HnswFindElementNeighbors(char *base, HnswElement element, HnswElement entryPoint, Relation index, const HnswTypeInfo * typeInfo, HnswSupport * support, int m, int efConstruction, bool existing)
 {
 	List	   *ep;
 	List	   *w;
@@ -1294,7 +1558,7 @@ HnswFindElementNeighbors(char *base, HnswElement element, HnswElement entryPoint
 	/* 1st phase: greedy search to insert level */
 	for (int lc = entryLevel; lc >= level + 1; lc--)
 	{
-		w = HnswSearchLayer(base, &q, ep, 1, lc, index, support, m, true, skipElement, NULL, NULL, true, NULL);
+		w = HnswSearchLayer(base, &q, ep, 1, lc, index, typeInfo, support, m, true, skipElement, NULL, NULL, true, NULL, false, NULL);
 		ep = w;
 	}
 
@@ -1313,7 +1577,7 @@ HnswFindElementNeighbors(char *base, HnswElement element, HnswElement entryPoint
 		List	   *lw = NIL;
 		ListCell   *lc2;
 
-		w = HnswSearchLayer(base, &q, ep, efConstruction, lc, index, support, m, true, skipElement, NULL, NULL, true, NULL);
+		w = HnswSearchLayer(base, &q, ep, efConstruction, lc, index, typeInfo, support, m, true, skipElement, NULL, NULL, true, NULL, false, NULL);
 
 		/* Convert search candidates to candidates */
 		foreach(lc2, w)
@@ -1370,13 +1634,44 @@ HnswGetTypeInfo(Relation index)
 
 	if (procinfo == NULL)
 	{
-		static const HnswTypeInfo typeInfo = {
-			.maxDimensions = HNSW_MAX_DIM,
-			.normalize = l2_normalize,
-			.checkValue = NULL
-		};
+		FmgrInfo	*distance_procinfo = index_getprocinfo(index, 1, HNSW_DISTANCE_PROC);
 
-		return (&typeInfo);
+		/*
+		 * In case of the L2 distance on single-precision (float) vectors (vector_l2_ops),
+		 * enables the simhash computation and distance estimation.
+		 */
+		if (HnswIsVectorL2Distance(distance_procinfo))
+		{
+			static const HnswTypeInfo typeInfo = {
+				.maxDimensions = HNSW_MAX_DIM,
+				.normalize = l2_normalize,
+				.checkValue = NULL,
+				.neighborMetadataBytes = HNSW_NEIGHBOR_VECTOR_L2_METADATA_BYTES,
+				.itemSize = HnswVectorItemSize,
+				.updateCenter = HnswVectorUpdateCenter,
+				.sumCenter = HnswVectorSumCenter,
+				.setNeighborMetadata = HnswSetVectorL2NeighborMetadata,
+				.estimateDistances = HnswEstimateVectorL2Distances
+			};
+
+			return (&typeInfo);
+		}
+		else
+		{
+			static const HnswTypeInfo typeInfo = {
+				.maxDimensions = HNSW_MAX_DIM,
+				.normalize = l2_normalize,
+				.checkValue = NULL,
+				.neighborMetadataBytes = 0,
+				.itemSize = NULL,
+				.updateCenter = NULL,
+				.sumCenter = NULL,
+				.setNeighborMetadata = NULL,
+				.estimateDistances = NULL
+			};
+
+			return (&typeInfo);
+		}
 	}
 	else
 		return (const HnswTypeInfo *) DatumGetPointer(FunctionCall0Coll(procinfo, InvalidOid));
@@ -1389,7 +1684,13 @@ hnsw_halfvec_support(PG_FUNCTION_ARGS)
 	static const HnswTypeInfo typeInfo = {
 		.maxDimensions = HNSW_MAX_DIM * 2,
 		.normalize = halfvec_l2_normalize,
-		.checkValue = NULL
+		.checkValue = NULL,
+		.neighborMetadataBytes = 0,
+		.itemSize = NULL,
+		.updateCenter = NULL,
+		.sumCenter = NULL,
+		.setNeighborMetadata = NULL,
+		.estimateDistances = NULL
 	};
 
 	PG_RETURN_POINTER(&typeInfo);
@@ -1402,7 +1703,13 @@ hnsw_bit_support(PG_FUNCTION_ARGS)
 	static const HnswTypeInfo typeInfo = {
 		.maxDimensions = HNSW_MAX_DIM * 32,
 		.normalize = NULL,
-		.checkValue = NULL
+		.checkValue = NULL,
+		.neighborMetadataBytes = 0,
+		.itemSize = NULL,
+		.updateCenter = NULL,
+		.sumCenter = NULL,
+		.setNeighborMetadata = NULL,
+		.estimateDistances = NULL
 	};
 
 	PG_RETURN_POINTER(&typeInfo);
@@ -1415,7 +1722,13 @@ hnsw_sparsevec_support(PG_FUNCTION_ARGS)
 	static const HnswTypeInfo typeInfo = {
 		.maxDimensions = SPARSEVEC_MAX_DIM,
 		.normalize = sparsevec_l2_normalize,
-		.checkValue = SparsevecCheckValue
+		.checkValue = SparsevecCheckValue,
+		.neighborMetadataBytes = 0,
+		.itemSize = NULL,
+		.updateCenter = NULL,
+		.sumCenter = NULL,
+		.setNeighborMetadata = NULL,
+		.estimateDistances = NULL
 	};
 
 	PG_RETURN_POINTER(&typeInfo);
diff --git a/src/hnswvacuum.c b/src/hnswvacuum.c
index 251d9d9..d319641 100644
--- a/src/hnswvacuum.c
+++ b/src/hnswvacuum.c
@@ -5,6 +5,7 @@
 #include "access/generic_xlog.h"
 #include "commands/vacuum.h"
 #include "hnsw.h"
+#include "hnswmeta.h"
 #include "storage/bufmgr.h"
 #include "storage/lmgr.h"
 #include "utils/memutils.h"
@@ -26,7 +27,7 @@ DeletedContains(tidhash_hash * deleted, ItemPointer indextid)
 static void
 RemoveHeapTids(HnswVacuumState * vacuumstate)
 {
-	BlockNumber blkno = HNSW_HEAD_BLKNO;
+	BlockNumber blkno = HnswGetHeadBlockNumber(vacuumstate->index);
 	HnswElement highestPoint = &vacuumstate->highestPoint;
 	Relation	index = vacuumstate->index;
 	BufferAccessStrategy bas = vacuumstate->bas;
@@ -138,6 +139,8 @@ static bool
 NeedsUpdated(HnswVacuumState * vacuumstate, HnswElement element)
 {
 	Relation	index = vacuumstate->index;
+	bool		neighborMetadata = HnswSupportNeighborMetadata(index);
+	const		HnswTypeInfo *typeInfo = HnswGetTypeInfo(index);
 	BufferAccessStrategy bas = vacuumstate->bas;
 	Buffer		buf;
 	Page		page;
@@ -154,7 +157,7 @@ NeedsUpdated(HnswVacuumState * vacuumstate, HnswElement element)
 	/* Check neighbors */
 	for (int i = 0; i < ntup->count; i++)
 	{
-		ItemPointer indextid = &ntup->indextids[i];
+		ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, i, typeInfo, neighborMetadata);
 
 		if (!ItemPointerIsValid(indextid))
 			continue;
@@ -170,7 +173,10 @@ NeedsUpdated(HnswVacuumState * vacuumstate, HnswElement element)
 	/* Also update if layer 0 is not full */
 	/* This could indicate too many candidates being deleted during insert */
 	if (!needsUpdated)
-		needsUpdated = !ItemPointerIsValid(&ntup->indextids[ntup->count - 1]);
+	{
+		ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, ntup->count - 1, typeInfo, neighborMetadata);
+		needsUpdated = !ItemPointerIsValid(indextid);
+	}
 
 	UnlockReleaseBuffer(buf);
 
@@ -184,6 +190,8 @@ static void
 RepairGraphElement(HnswVacuumState * vacuumstate, HnswElement element, HnswElement entryPoint)
 {
 	Relation	index = vacuumstate->index;
+	bool		neighborMetadata = HnswSupportNeighborMetadata(index);
+	const		HnswTypeInfo *typeInfo = HnswGetTypeInfo(index);
 	HnswSupport *support = &vacuumstate->support;
 	Buffer		buf;
 	Page		page;
@@ -192,7 +200,7 @@ RepairGraphElement(HnswVacuumState * vacuumstate, HnswElement element, HnswEleme
 	int			efConstruction = vacuumstate->efConstruction;
 	BufferAccessStrategy bas = vacuumstate->bas;
 	HnswNeighborTuple ntup = vacuumstate->ntup;
-	Size		ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(element->level, m);
+	Size		ntupSize = HNSW_NEIGHBOR_TUPLE_SIZE(element->level, m, typeInfo, neighborMetadata);
 	char	   *base = NULL;
 
 	/* Skip if element is entry point */
@@ -204,14 +212,14 @@ RepairGraphElement(HnswVacuumState * vacuumstate, HnswElement element, HnswEleme
 	element->heaptidsLength = 0;
 
 	/* Find neighbors for element, skipping itself */
-	HnswFindElementNeighbors(base, element, entryPoint, index, support, m, efConstruction, true);
+	HnswFindElementNeighbors(base, element, entryPoint, index, typeInfo, support, m, efConstruction, true);
 
 	/* Zero memory for each element */
 	MemSet(ntup, 0, HNSW_TUPLE_ALLOC_SIZE);
 
 	/* Update neighbor tuple */
 	/* Do this before getting page to minimize locking */
-	HnswSetNeighborTuple(base, ntup, element, m);
+	HnswSetNeighborTuple(base, ntup, element, m, typeInfo, support, vacuumstate->neighborMetadataState, neighborMetadata);
 
 	/* Get neighbor page */
 	buf = ReadBufferExtended(index, MAIN_FORKNUM, element->neighborPage, RBM_NORMAL, bas);
@@ -228,7 +236,7 @@ RepairGraphElement(HnswVacuumState * vacuumstate, HnswElement element, HnswEleme
 	UnlockReleaseBuffer(buf);
 
 	/* Update neighbors */
-	HnswUpdateNeighborsOnDisk(index, support, element, m, true, false);
+	HnswUpdateNeighborsOnDisk(index, typeInfo, support, element, m, true, false, neighborMetadata);
 }
 
 /*
@@ -323,7 +331,7 @@ RepairGraph(HnswVacuumState * vacuumstate)
 {
 	Relation	index = vacuumstate->index;
 	BufferAccessStrategy bas = vacuumstate->bas;
-	BlockNumber blkno = HNSW_HEAD_BLKNO;
+	BlockNumber blkno = HnswGetHeadBlockNumber(index);
 
 	/*
 	 * Wait for inserts to complete. Inserts before this point may have
@@ -436,9 +444,11 @@ RepairGraph(HnswVacuumState * vacuumstate)
 static void
 MarkDeleted(HnswVacuumState * vacuumstate)
 {
-	BlockNumber blkno = HNSW_HEAD_BLKNO;
+	BlockNumber blkno = HnswGetHeadBlockNumber(vacuumstate->index);
 	BlockNumber insertPage = InvalidBlockNumber;
 	Relation	index = vacuumstate->index;
+	bool		neighborMetadata = HnswSupportNeighborMetadata(index);
+	const		HnswTypeInfo *typeInfo = HnswGetTypeInfo(index);
 	BufferAccessStrategy bas = vacuumstate->bas;
 
 	/*
@@ -525,7 +535,10 @@ MarkDeleted(HnswVacuumState * vacuumstate)
 
 			/* Overwrite neighbors */
 			for (int i = 0; i < ntup->count; i++)
-				ItemPointerSetInvalid(&ntup->indextids[i]);
+			{
+				ItemPointer indextid = HnswNeighborEntryItemPointerAccess(ntup->entries, i, typeInfo, neighborMetadata);
+				ItemPointerSetInvalid(indextid);
+			}
 
 			/* Increment version */
 			/* This is used to avoid incorrect reads for iterative scans */
@@ -591,6 +604,9 @@ InitVacuumState(HnswVacuumState * vacuumstate, IndexVacuumInfo *info, IndexBulkD
 	/* Get m from metapage */
 	HnswGetMetaPageInfo(index, &vacuumstate->m, NULL);
 
+	/* Load neighbor metadata state */
+	vacuumstate->neighborMetadataState = HnswLoadNeighborMetadataStateFromDisk(index);
+
 	/* Create hash table */
 	vacuumstate->deleted = tidhash_create(CurrentMemoryContext, 256, NULL);
 }
diff --git a/src/ivfbuild.c b/src/ivfbuild.c
index 54a5be5..2bd9223 100644
--- a/src/ivfbuild.c
+++ b/src/ivfbuild.c
@@ -403,7 +403,12 @@ FreeBuildState(IvfflatBuildState * buildstate)
 static void
 ComputeCenters(IvfflatBuildState * buildstate)
 {
-	int			numSamples;
+	int 				numSamples;
+	const KmeansInfo 	kmeansInfo = {
+		.procinfo = index_getprocinfo(buildstate->index, 1, IVFFLAT_KMEANS_DISTANCE_PROC),
+		.normprocinfo = IvfflatOptionalProcInfo(buildstate->index, IVFFLAT_KMEANS_NORM_PROC),
+		.collation = buildstate->index->rd_indcollation[0]
+	};
 
 	pgstat_progress_update_param(PROGRESS_CREATEIDX_SUBPHASE, PROGRESS_IVFFLAT_PHASE_KMEANS);
 
@@ -434,7 +439,7 @@ ComputeCenters(IvfflatBuildState * buildstate)
 	}
 
 	/* Calculate centers */
-	IvfflatBench("k-means", IvfflatKmeans(buildstate->index, buildstate->samples, buildstate->centers, buildstate->typeInfo));
+	IvfflatBench("k-means", IvfflatKmeans(buildstate->index, buildstate->samples, buildstate->centers, buildstate->typeInfo, &kmeansInfo));
 
 	/* Free samples before we allocate more memory */
 	VectorArrayFree(buildstate->samples);
diff --git a/src/ivfflat.h b/src/ivfflat.h
index c296b66..a73bf5f 100644
--- a/src/ivfflat.h
+++ b/src/ivfflat.h
@@ -166,6 +166,13 @@ typedef struct IvfflatTypeInfo
 	void		(*sumCenter) (Pointer v, float *x);
 }			IvfflatTypeInfo;
 
+typedef struct KmeansInfo
+{
+	FmgrInfo   *procinfo;
+	FmgrInfo   *normprocinfo;
+	Oid			collation;
+} 			KmeansInfo;
+
 typedef struct IvfflatBuildState
 {
 	/* Info */
@@ -303,7 +310,7 @@ VectorArraySet(VectorArray arr, int offset, Pointer val)
 /* Methods */
 VectorArray VectorArrayInit(int maxlen, int dimensions, Size itemsize);
 void		VectorArrayFree(VectorArray arr);
-void		IvfflatKmeans(Relation index, VectorArray samples, VectorArray centers, const IvfflatTypeInfo * typeInfo);
+void		IvfflatKmeans(Relation index, VectorArray samples, VectorArray centers, const IvfflatTypeInfo * typeInfo, const KmeansInfo * kmeansInfo);
 FmgrInfo   *IvfflatOptionalProcInfo(Relation index, uint16 procnum);
 Datum		IvfflatNormValue(const IvfflatTypeInfo * typeInfo, Oid collation, Datum value);
 bool		IvfflatCheckNorm(FmgrInfo *procinfo, Oid collation, Datum value);
diff --git a/src/ivfkmeans.c b/src/ivfkmeans.c
index 4b6d14f..60a4016 100644
--- a/src/ivfkmeans.c
+++ b/src/ivfkmeans.c
@@ -19,7 +19,7 @@
  * https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf
  */
 static void
-InitCenters(Relation index, VectorArray samples, VectorArray centers, float *lowerBound)
+InitCenters(Relation index, VectorArray samples, VectorArray centers, float *lowerBound, const KmeansInfo * kmeansInfo)
 {
 	FmgrInfo   *procinfo;
 	Oid			collation;
@@ -28,8 +28,8 @@ InitCenters(Relation index, VectorArray samples, VectorArray centers, float *low
 	int			numCenters = centers->maxlen;
 	int			numSamples = samples->length;
 
-	procinfo = index_getprocinfo(index, 1, IVFFLAT_KMEANS_DISTANCE_PROC);
-	collation = index->rd_indcollation[0];
+	procinfo = kmeansInfo->procinfo;
+	collation = kmeansInfo->collation;
 
 	/* Choose an initial center uniformly at random */
 	VectorArraySet(centers, 0, VectorArrayGet(samples, RandomInt() % samples->length));
@@ -120,11 +120,11 @@ NormCenters(const IvfflatTypeInfo * typeInfo, Oid collation, VectorArray centers
  * Quick approach if we have no data
  */
 static void
-RandomCenters(Relation index, VectorArray centers, const IvfflatTypeInfo * typeInfo)
+RandomCenters(Relation index, VectorArray centers, const IvfflatTypeInfo * typeInfo, const KmeansInfo * kmeansInfo)
 {
 	int			dimensions = centers->dim;
-	FmgrInfo   *normprocinfo = IvfflatOptionalProcInfo(index, IVFFLAT_KMEANS_NORM_PROC);
-	Oid			collation = index->rd_indcollation[0];
+	FmgrInfo   *normprocinfo = kmeansInfo->normprocinfo;
+	Oid			collation = kmeansInfo->collation;
 	float	   *x = (float *) palloc(sizeof(float) * dimensions);
 
 	/* Fill with random data */
@@ -256,7 +256,7 @@ ComputeNewCenters(VectorArray samples, float *agg, VectorArray newCenters, int *
  * https://www.aaai.org/Papers/ICML/2003/ICML03-022.pdf
  */
 static void
-ElkanKmeans(Relation index, VectorArray samples, VectorArray centers, const IvfflatTypeInfo * typeInfo)
+ElkanKmeans(Relation index, VectorArray samples, VectorArray centers, const IvfflatTypeInfo * typeInfo, const KmeansInfo * kmeansInfo)
 {
 	FmgrInfo   *procinfo;
 	FmgrInfo   *normprocinfo;
@@ -303,9 +303,9 @@ ElkanKmeans(Relation index, VectorArray samples, VectorArray centers, const Ivff
 		elog(ERROR, "Indexing overflow detected. Please report a bug.");
 
 	/* Set support functions */
-	procinfo = index_getprocinfo(index, 1, IVFFLAT_KMEANS_DISTANCE_PROC);
-	normprocinfo = IvfflatOptionalProcInfo(index, IVFFLAT_KMEANS_NORM_PROC);
-	collation = index->rd_indcollation[0];
+	procinfo = kmeansInfo->procinfo;
+	normprocinfo = kmeansInfo->normprocinfo;
+	collation = kmeansInfo->collation;
 
 	/* Allocate space */
 	/* Use float instead of double to save memory */
@@ -327,7 +327,7 @@ ElkanKmeans(Relation index, VectorArray samples, VectorArray centers, const Ivff
 #endif
 
 	/* Pick initial centers */
-	InitCenters(index, samples, centers, lowerBound);
+	InitCenters(index, samples, centers, lowerBound, kmeansInfo);
 
 	/* Assign each x to its closest initial center c(x) = argmin d(x,c) */
 	for (int64 j = 0; j < numSamples; j++)
@@ -560,7 +560,7 @@ CheckCenters(Relation index, VectorArray centers, const IvfflatTypeInfo * typeIn
  * We use spherical k-means for inner product and cosine
  */
 void
-IvfflatKmeans(Relation index, VectorArray samples, VectorArray centers, const IvfflatTypeInfo * typeInfo)
+IvfflatKmeans(Relation index, VectorArray samples, VectorArray centers, const IvfflatTypeInfo * typeInfo, const KmeansInfo * kmeansInfo)
 {
 	MemoryContext kmeansCtx = AllocSetContextCreate(CurrentMemoryContext,
 													"Ivfflat kmeans temporary context",
@@ -568,9 +568,9 @@ IvfflatKmeans(Relation index, VectorArray samples, VectorArray centers, const Iv
 	MemoryContext oldCtx = MemoryContextSwitchTo(kmeansCtx);
 
 	if (samples->length == 0)
-		RandomCenters(index, centers, typeInfo);
+		RandomCenters(index, centers, typeInfo, kmeansInfo);
 	else
-		ElkanKmeans(index, samples, centers, typeInfo);
+		ElkanKmeans(index, samples, centers, typeInfo, kmeansInfo);
 
 	CheckCenters(index, centers, typeInfo);
 
diff --git a/test/expected/hnsw_vector.out b/test/expected/hnsw_vector.out
index 29ea724..a81a24f 100644
--- a/test/expected/hnsw_vector.out
+++ b/test/expected/hnsw_vector.out
@@ -3,6 +3,9 @@ SET enable_seqscan = off;
 CREATE TABLE t (val vector(3));
 INSERT INTO t (val) VALUES ('[0,0,0]'), ('[1,2,3]'), ('[1,1,1]'), (NULL);
 CREATE INDEX ON t USING hnsw (val vector_l2_ops);
+NOTICE:  hnsw index metadata created with little data
+DETAIL:  This will cause low recall.
+HINT:  Drop the index until the table has more data.
 INSERT INTO t (val) VALUES ('[1,2,4]');
 SELECT * FROM t ORDER BY val <-> '[3,3,3]';
    val   
@@ -26,6 +29,9 @@ SELECT COUNT(*) FROM t;
 (1 row)
 
 TRUNCATE t;
+NOTICE:  hnsw index metadata created with little data
+DETAIL:  This will cause low recall.
+HINT:  Drop the index until the table has more data.
 SELECT * FROM t ORDER BY val <-> '[3,3,3]';
  val 
 -----
@@ -104,6 +110,9 @@ DROP TABLE t;
 CREATE TABLE t (val vector(3));
 INSERT INTO t (val) VALUES ('[0,0,0]'), ('[1,2,3]'), ('[1,1,1]'), (NULL);
 CREATE INDEX ON t USING hnsw (val vector_l2_ops);
+NOTICE:  hnsw index metadata created with little data
+DETAIL:  This will cause low recall.
+HINT:  Drop the index until the table has more data.
 SET hnsw.iterative_scan = strict_order;
 SET hnsw.ef_search = 1;
 SELECT * FROM t ORDER BY val <-> '[3,3,3]';
@@ -130,6 +139,9 @@ DROP TABLE t;
 CREATE UNLOGGED TABLE t (val vector(3));
 INSERT INTO t (val) VALUES ('[0,0,0]'), ('[1,2,3]'), ('[1,1,1]'), (NULL);
 CREATE INDEX ON t USING hnsw (val vector_l2_ops);
+NOTICE:  hnsw index metadata created with little data
+DETAIL:  This will cause low recall.
+HINT:  Drop the index until the table has more data.
 SELECT * FROM t ORDER BY val <-> '[3,3,3]';
    val   
 ---------
diff --git a/test/t/012_hnsw_vector_build_recall.pl b/test/t/012_hnsw_vector_build_recall.pl
index 9358874..860aa4f 100644
--- a/test/t/012_hnsw_vector_build_recall.pl
+++ b/test/t/012_hnsw_vector_build_recall.pl
@@ -55,7 +55,7 @@ $node->start;
 $node->safe_psql("postgres", "CREATE EXTENSION vector;");
 $node->safe_psql("postgres", "CREATE TABLE tst (i int4, v vector(3));");
 $node->safe_psql("postgres",
-	"INSERT INTO tst SELECT i, ARRAY[$array_sql] FROM generate_series(1, 10000) i;"
+	"INSERT INTO tst SELECT i, ARRAY[$array_sql] FROM generate_series(1, 30000) i;"
 );
 
 # Generate queries
@@ -112,10 +112,12 @@ for my $i (0 .. $#operators)
 
 	# Build index in parallel on disk
 	# Set parallel_workers on table to use workers with low maintenance_work_mem
+	# NOTE: Due to PQ encoding, the required maintenance_work_mem changes, so we're increasing the setting value
+	# while tripling the amount of data inserted accordingly
 	($ret, $stdout, $stderr) = $node->psql("postgres", qq(
 		ALTER TABLE tst SET (parallel_workers = 2);
 		SET client_min_messages = DEBUG;
-		SET maintenance_work_mem = '4MB';
+		SET maintenance_work_mem = '14MB';
 		CREATE INDEX idx ON tst USING hnsw (v $opclass);
 		ALTER TABLE tst RESET (parallel_workers);
 	));
diff --git a/test/t/016_hnsw_inserts.pl b/test/t/016_hnsw_inserts.pl
index 2b2f479..f45e41e 100644
--- a/test/t/016_hnsw_inserts.pl
+++ b/test/t/016_hnsw_inserts.pl
@@ -40,8 +40,10 @@ for my $i (1 .. 20)
 		}
 	);
 
+	# TODO When candidate pruning enabled, not all candidates can be returned, making results non-deterministic
 	my $count = $node->safe_psql("postgres", qq(
 		SET enable_seqscan = off;
+		SET hnsw.candidate_pruning = off;
 		SELECT COUNT(*) FROM (SELECT v FROM tst ORDER BY v <-> (SELECT v FROM tst LIMIT 1)) t;
 	));
 	is($count, 10);
diff --git a/test/t/017_hnsw_filtering.pl b/test/t/017_hnsw_filtering.pl
index afa2a1c..00b6a9d 100644
--- a/test/t/017_hnsw_filtering.pl
+++ b/test/t/017_hnsw_filtering.pl
@@ -19,8 +19,10 @@ $node->start;
 $node->safe_psql("postgres", "CREATE EXTENSION vector;");
 $node->safe_psql("postgres", "CREATE TABLE tst (i int4, v vector($dim), c int4, t text);");
 $node->safe_psql("postgres", "CREATE TABLE cat (i int4 PRIMARY KEY, t text, b boolean);");
+# Increase the number of rows in tst because the cost of index access paths increases due to index size growth
+# from neighbor metadata, resulting in partial index not being selected in the last test
 $node->safe_psql("postgres",
-	"INSERT INTO tst SELECT i, ARRAY[$array_sql], i % $nc, 'test ' || i FROM generate_series(1, 10000) i;"
+	"INSERT INTO tst SELECT i, ARRAY[$array_sql], i % $nc, 'test ' || i FROM generate_series(1, 30000) i;"
 );
 $node->safe_psql("postgres",
 	"INSERT INTO cat SELECT i, 'cat ' || i, i % 5 = 0 FROM generate_series(1, $nc) i;"
diff --git a/test/t/039_hnsw_cost.pl b/test/t/039_hnsw_cost.pl
index 97ea5e7..96106e5 100644
--- a/test/t/039_hnsw_cost.pl
+++ b/test/t/039_hnsw_cost.pl
@@ -20,8 +20,10 @@ for my $dim (@dims)
 
 	# Create table and index
 	$node->safe_psql("postgres", "CREATE TABLE tst (i int4, v vector($dim));");
+	# Increase the number of rows in tst because the cost of index access paths increases due to index size growth
+	# from neighbor metadata, resulting in index scans not being selected in the follwoing tests
 	$node->safe_psql("postgres",
-		"INSERT INTO tst SELECT i, ARRAY[$array_sql] FROM generate_series(1, 2000) i;"
+		"INSERT INTO tst SELECT i, ARRAY[$array_sql] FROM generate_series(1, 6000) i;"
 	);
 	$node->safe_psql("postgres", "CREATE INDEX idx ON tst USING hnsw (v vector_l2_ops);");
 	$node->safe_psql("postgres", "ANALYZE tst;");
@@ -44,7 +46,7 @@ for my $dim (@dims)
 	# Recreate index for performance
 	$node->safe_psql("postgres", "DROP INDEX idx;");
 	$node->safe_psql("postgres",
-		"INSERT INTO tst SELECT i, ARRAY[$array_sql] FROM generate_series(2001, 6000) i;"
+		"INSERT INTO tst SELECT i, ARRAY[$array_sql] FROM generate_series(6001, 18000) i;"
 	);
 	$node->safe_psql("postgres", "CREATE INDEX idx ON tst USING hnsw (v vector_l2_ops);");
 	$node->safe_psql("postgres", "ANALYZE tst;");
diff --git a/test/t/043_hnsw_iterative_scan.pl b/test/t/043_hnsw_iterative_scan.pl
index e75c697..23f8fff 100644
--- a/test/t/043_hnsw_iterative_scan.pl
+++ b/test/t/043_hnsw_iterative_scan.pl
@@ -24,11 +24,13 @@ $node->safe_psql("postgres", qq(
 	CREATE INDEX ON tst USING hnsw (v vector_l2_ops)
 ));
 
+# TODO When candidate pruning enabled, not all candidates can be returned, making results non-deterministic
 my $count = $node->safe_psql("postgres", qq(
 	SET enable_seqscan = off;
 	SET hnsw.iterative_scan = relaxed_order;
 	SET hnsw.max_scan_tuples = 100000;
 	SET hnsw.scan_mem_multiplier = 2;
+	SET hnsw.candidate_pruning = off;
 	SELECT COUNT(*) FROM (SELECT v FROM tst WHERE i % 10000 = 0 ORDER BY v <-> (SELECT v FROM tst LIMIT 1) LIMIT 11) t;
 ));
 is($count, 10);
